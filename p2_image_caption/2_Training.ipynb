{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "The model is following the model described in the paper in https://arxiv.org/pdf/1411.4555.pdf, figure 3.1. The CNN encoder is using the pre-trained Resnet-50, with the last layer replaced by fully connected layer. And then the decoder takes the output from the encoder, feed it into the embedding layer, and then to the LSTM layer followed by a fully connected layer.\n",
    "\n",
    "In the implementation, i am using \n",
    "- a minimum word count threshold of 5\n",
    "- batch size of 64\n",
    "- Following the paper https://arxiv.org/pdf/1411.4555.pdf, the embedding and hidden size both are set to 512.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "The transform pipeline is left as it is. The pipeline first reize the image to a fixed size, and then randomly crop the image to a size of 224x224x3, which is the size expected by the CNN encoder.\n",
    "\n",
    "Then the pipeline will randomly horizontally flipped the image, so we can have more variety of the training data to train the network. Finally the image is normalized which is pretty standard in training CNN network.\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.bn.parameters())\n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "Using the pretrained ResNet-50, so we have to freeze all the layers except the last one, and replace the last layer in the CNN encoder with a fully connected layers, and i also apply batch normalization to the encoder output. So These set of parameters needs to be trained.\n",
    "\n",
    "As on the decoder side, we need to train all of the parameters for the decoder.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:**\n",
    "Adam Optimizer was used, it is commonly used and effective optimizers. Adams can be looked at as a combination of RMSProp and Stochastic Gradient Descent with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 373/414113 [00:00<01:53, 3633.51it/s]\u001b[A\n",
      "  0%|          | 805/414113 [00:00<01:48, 3813.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=1.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1245/414113 [00:00<01:43, 3972.63it/s]\u001b[A\n",
      "  0%|          | 1689/414113 [00:00<01:40, 4100.03it/s]\u001b[A\n",
      "  1%|          | 2130/414113 [00:00<01:38, 4187.78it/s]\u001b[A\n",
      "  1%|          | 2574/414113 [00:00<01:36, 4259.50it/s]\u001b[A\n",
      "  1%|          | 2999/414113 [00:00<01:36, 4256.19it/s]\u001b[A\n",
      "  1%|          | 3418/414113 [00:00<01:36, 4235.29it/s]\u001b[A\n",
      "  1%|          | 3854/414113 [00:00<01:36, 4271.74it/s]\u001b[A\n",
      "  1%|          | 4297/414113 [00:01<01:34, 4316.28it/s]\u001b[A\n",
      "  1%|          | 4736/414113 [00:01<01:34, 4336.24it/s]\u001b[A\n",
      "  1%|          | 5170/414113 [00:01<01:34, 4336.18it/s]\u001b[A\n",
      "  1%|▏         | 5601/414113 [00:01<01:34, 4325.85it/s]\u001b[A\n",
      "  1%|▏         | 6037/414113 [00:01<01:34, 4333.50it/s]\u001b[A\n",
      "  2%|▏         | 6476/414113 [00:01<01:33, 4348.70it/s]\u001b[A\n",
      "  2%|▏         | 6915/414113 [00:01<01:33, 4358.39it/s]\u001b[A\n",
      "  2%|▏         | 7350/414113 [00:01<01:38, 4147.25it/s]\u001b[A\n",
      "  2%|▏         | 7767/414113 [00:01<01:38, 4121.57it/s]\u001b[A\n",
      "  2%|▏         | 8182/414113 [00:01<01:38, 4128.39it/s]\u001b[A\n",
      "  2%|▏         | 8605/414113 [00:02<01:37, 4156.07it/s]\u001b[A\n",
      "  2%|▏         | 9027/414113 [00:02<01:37, 4173.04it/s]\u001b[A\n",
      "  2%|▏         | 9445/414113 [00:02<01:36, 4172.66it/s]\u001b[A\n",
      "  2%|▏         | 9863/414113 [00:02<01:36, 4167.56it/s]\u001b[A\n",
      "  2%|▏         | 10280/414113 [00:02<01:37, 4152.54it/s]\u001b[A\n",
      "  3%|▎         | 10709/414113 [00:02<01:36, 4192.70it/s]\u001b[A\n",
      "  3%|▎         | 11148/414113 [00:02<01:34, 4244.20it/s]\u001b[A\n",
      "  3%|▎         | 11585/414113 [00:02<01:34, 4278.67it/s]\u001b[A\n",
      "  3%|▎         | 12014/414113 [00:02<01:34, 4248.48it/s]\u001b[A\n",
      "  3%|▎         | 12440/414113 [00:02<01:35, 4220.16it/s]\u001b[A\n",
      "  3%|▎         | 12863/414113 [00:03<01:35, 4213.77it/s]\u001b[A\n",
      "  3%|▎         | 13285/414113 [00:03<01:35, 4204.67it/s]\u001b[A\n",
      "  3%|▎         | 13706/414113 [00:03<01:35, 4192.29it/s]\u001b[A\n",
      "  3%|▎         | 14129/414113 [00:03<01:35, 4200.96it/s]\u001b[A\n",
      "  4%|▎         | 14559/414113 [00:03<01:34, 4228.38it/s]\u001b[A\n",
      "  4%|▎         | 14982/414113 [00:03<01:35, 4195.87it/s]\u001b[A\n",
      "  4%|▎         | 15403/414113 [00:03<01:34, 4197.66it/s]\u001b[A\n",
      "  4%|▍         | 15843/414113 [00:03<01:33, 4255.84it/s]\u001b[A\n",
      "  4%|▍         | 16274/414113 [00:03<01:33, 4271.41it/s]\u001b[A\n",
      "  4%|▍         | 16719/414113 [00:03<01:31, 4322.31it/s]\u001b[A\n",
      "  4%|▍         | 17163/414113 [00:04<01:31, 4356.41it/s]\u001b[A\n",
      "  4%|▍         | 17602/414113 [00:04<01:30, 4363.83it/s]\u001b[A\n",
      "  4%|▍         | 18039/414113 [00:04<01:30, 4364.66it/s]\u001b[A\n",
      "  4%|▍         | 18489/414113 [00:04<01:29, 4401.58it/s]\u001b[A\n",
      "  5%|▍         | 18935/414113 [00:04<01:29, 4418.38it/s]\u001b[A\n",
      "  5%|▍         | 19377/414113 [00:04<01:29, 4409.70it/s]\u001b[A\n",
      "  5%|▍         | 19819/414113 [00:04<01:29, 4410.91it/s]\u001b[A\n",
      "  5%|▍         | 20261/414113 [00:04<01:32, 4251.54it/s]\u001b[A\n",
      "  5%|▍         | 20696/414113 [00:04<01:31, 4278.83it/s]\u001b[A\n",
      "  5%|▌         | 21147/414113 [00:04<01:30, 4344.06it/s]\u001b[A\n",
      "  5%|▌         | 21592/414113 [00:05<01:29, 4373.28it/s]\u001b[A\n",
      "  5%|▌         | 22031/414113 [00:05<01:29, 4361.76it/s]\u001b[A\n",
      "  5%|▌         | 22468/414113 [00:05<01:29, 4353.85it/s]\u001b[A\n",
      "  6%|▌         | 22919/414113 [00:05<01:28, 4398.97it/s]\u001b[A\n",
      "  6%|▌         | 23360/414113 [00:05<01:29, 4383.17it/s]\u001b[A\n",
      "  6%|▌         | 23799/414113 [00:05<01:31, 4270.84it/s]\u001b[A\n",
      "  6%|▌         | 24245/414113 [00:05<01:30, 4325.36it/s]\u001b[A\n",
      "  6%|▌         | 24684/414113 [00:05<01:29, 4342.58it/s]\u001b[A\n",
      "  6%|▌         | 25128/414113 [00:05<01:29, 4368.94it/s]\u001b[A\n",
      "  6%|▌         | 25573/414113 [00:05<01:28, 4390.77it/s]\u001b[A\n",
      "  6%|▋         | 26016/414113 [00:06<01:28, 4402.06it/s]\u001b[A\n",
      "  6%|▋         | 26457/414113 [00:06<01:28, 4395.89it/s]\u001b[A\n",
      "  6%|▋         | 26906/414113 [00:06<01:27, 4423.30it/s]\u001b[A\n",
      "  7%|▋         | 27349/414113 [00:06<01:28, 4380.00it/s]\u001b[A\n",
      "  7%|▋         | 27788/414113 [00:06<01:28, 4381.98it/s]\u001b[A\n",
      "  7%|▋         | 28230/414113 [00:06<01:27, 4391.39it/s]\u001b[A\n",
      "  7%|▋         | 28673/414113 [00:06<01:27, 4401.47it/s]\u001b[A\n",
      "  7%|▋         | 29118/414113 [00:06<01:27, 4413.07it/s]\u001b[A\n",
      "  7%|▋         | 29562/414113 [00:06<01:27, 4418.48it/s]\u001b[A\n",
      "  7%|▋         | 30014/414113 [00:06<01:26, 4445.91it/s]\u001b[A\n",
      "  7%|▋         | 30463/414113 [00:07<01:26, 4454.45it/s]\u001b[A\n",
      "  7%|▋         | 30909/414113 [00:07<01:26, 4446.19it/s]\u001b[A\n",
      "  8%|▊         | 31354/414113 [00:07<01:26, 4423.45it/s]\u001b[A\n",
      "  8%|▊         | 31797/414113 [00:07<01:26, 4409.39it/s]\u001b[A\n",
      "  8%|▊         | 32238/414113 [00:07<01:28, 4314.26it/s]\u001b[A\n",
      "  8%|▊         | 32679/414113 [00:07<01:27, 4341.07it/s]\u001b[A\n",
      "  8%|▊         | 33114/414113 [00:07<01:28, 4301.57it/s]\u001b[A\n",
      "  8%|▊         | 33545/414113 [00:07<01:29, 4235.04it/s]\u001b[A\n",
      "  8%|▊         | 33969/414113 [00:07<01:30, 4218.53it/s]\u001b[A\n",
      "  8%|▊         | 34392/414113 [00:07<01:29, 4219.66it/s]\u001b[A\n",
      "  8%|▊         | 34815/414113 [00:08<01:31, 4153.95it/s]\u001b[A\n",
      "  9%|▊         | 35235/414113 [00:08<01:30, 4165.12it/s]\u001b[A\n",
      "  9%|▊         | 35652/414113 [00:08<01:32, 4103.01it/s]\u001b[A\n",
      "  9%|▊         | 36066/414113 [00:08<01:31, 4113.64it/s]\u001b[A\n",
      "  9%|▉         | 36478/414113 [00:08<01:31, 4113.61it/s]\u001b[A\n",
      "  9%|▉         | 36922/414113 [00:08<01:29, 4204.09it/s]\u001b[A\n",
      "  9%|▉         | 37352/414113 [00:08<01:29, 4230.48it/s]\u001b[A\n",
      "  9%|▉         | 37792/414113 [00:08<01:27, 4277.65it/s]\u001b[A\n",
      "  9%|▉         | 38226/414113 [00:08<01:27, 4295.73it/s]\u001b[A\n",
      "  9%|▉         | 38668/414113 [00:09<01:26, 4330.15it/s]\u001b[A\n",
      "  9%|▉         | 39102/414113 [00:09<01:27, 4307.86it/s]\u001b[A\n",
      " 10%|▉         | 39547/414113 [00:09<01:26, 4347.74it/s]\u001b[A\n",
      " 10%|▉         | 39983/414113 [00:09<01:26, 4309.48it/s]\u001b[A\n",
      " 10%|▉         | 40415/414113 [00:09<01:27, 4268.85it/s]\u001b[A\n",
      " 10%|▉         | 40870/414113 [00:09<01:25, 4348.05it/s]\u001b[A\n",
      " 10%|▉         | 41306/414113 [00:09<01:26, 4334.12it/s]\u001b[A\n",
      " 10%|█         | 41748/414113 [00:09<01:25, 4359.29it/s]\u001b[A\n",
      " 10%|█         | 42185/414113 [00:09<01:26, 4319.81it/s]\u001b[A\n",
      " 10%|█         | 42619/414113 [00:09<01:25, 4323.65it/s]\u001b[A\n",
      " 10%|█         | 43064/414113 [00:10<01:25, 4359.29it/s]\u001b[A\n",
      " 11%|█         | 43501/414113 [00:10<01:25, 4315.13it/s]\u001b[A\n",
      " 11%|█         | 43933/414113 [00:10<01:26, 4295.96it/s]\u001b[A\n",
      " 11%|█         | 44367/414113 [00:10<01:25, 4308.64it/s]\u001b[A\n",
      " 11%|█         | 44799/414113 [00:10<01:27, 4229.01it/s]\u001b[A\n",
      " 11%|█         | 45248/414113 [00:10<01:25, 4302.21it/s]\u001b[A\n",
      " 11%|█         | 45687/414113 [00:10<01:25, 4325.30it/s]\u001b[A\n",
      " 11%|█         | 46129/414113 [00:10<01:24, 4353.15it/s]\u001b[A\n",
      " 11%|█         | 46568/414113 [00:10<01:24, 4363.78it/s]\u001b[A\n",
      " 11%|█▏        | 47005/414113 [00:10<01:24, 4356.98it/s]\u001b[A\n",
      " 11%|█▏        | 47441/414113 [00:11<01:24, 4333.10it/s]\u001b[A\n",
      " 12%|█▏        | 47877/414113 [00:11<01:24, 4341.13it/s]\u001b[A\n",
      " 12%|█▏        | 48320/414113 [00:11<01:23, 4364.81it/s]\u001b[A\n",
      " 12%|█▏        | 48757/414113 [00:11<01:24, 4339.44it/s]\u001b[A\n",
      " 12%|█▏        | 49201/414113 [00:11<01:23, 4368.24it/s]\u001b[A\n",
      " 12%|█▏        | 49647/414113 [00:11<01:22, 4393.01it/s]\u001b[A\n",
      " 12%|█▏        | 50087/414113 [00:11<01:23, 4355.97it/s]\u001b[A\n",
      " 12%|█▏        | 50527/414113 [00:11<01:23, 4368.48it/s]\u001b[A\n",
      " 12%|█▏        | 50974/414113 [00:11<01:22, 4395.82it/s]\u001b[A\n",
      " 12%|█▏        | 51414/414113 [00:11<01:22, 4378.11it/s]\u001b[A\n",
      " 13%|█▎        | 51852/414113 [00:12<01:22, 4372.45it/s]\u001b[A\n",
      " 13%|█▎        | 52295/414113 [00:12<01:22, 4387.58it/s]\u001b[A\n",
      " 13%|█▎        | 52735/414113 [00:12<01:22, 4387.73it/s]\u001b[A\n",
      " 13%|█▎        | 53174/414113 [00:12<01:24, 4293.26it/s]\u001b[A\n",
      " 13%|█▎        | 53620/414113 [00:12<01:23, 4341.89it/s]\u001b[A\n",
      " 13%|█▎        | 54069/414113 [00:12<01:22, 4383.20it/s]\u001b[A\n",
      " 13%|█▎        | 54510/414113 [00:12<01:21, 4391.04it/s]\u001b[A\n",
      " 13%|█▎        | 54950/414113 [00:12<01:22, 4341.86it/s]\u001b[A\n",
      " 13%|█▎        | 55387/414113 [00:12<01:22, 4350.20it/s]\u001b[A\n",
      " 13%|█▎        | 55823/414113 [00:12<01:22, 4352.47it/s]\u001b[A\n",
      " 14%|█▎        | 56264/414113 [00:13<01:21, 4369.30it/s]\u001b[A\n",
      " 14%|█▎        | 56702/414113 [00:13<01:21, 4366.75it/s]\u001b[A\n",
      " 14%|█▍        | 57141/414113 [00:13<01:21, 4372.14it/s]\u001b[A\n",
      " 14%|█▍        | 57589/414113 [00:13<01:20, 4403.87it/s]\u001b[A\n",
      " 14%|█▍        | 58039/414113 [00:13<01:20, 4431.40it/s]\u001b[A\n",
      " 14%|█▍        | 58489/414113 [00:13<01:19, 4450.02it/s]\u001b[A\n",
      " 14%|█▍        | 58935/414113 [00:13<01:19, 4453.00it/s]\u001b[A\n",
      " 14%|█▍        | 59381/414113 [00:13<01:19, 4440.38it/s]\u001b[A\n",
      " 14%|█▍        | 59831/414113 [00:13<01:19, 4455.80it/s]\u001b[A\n",
      " 15%|█▍        | 60277/414113 [00:13<01:19, 4456.22it/s]\u001b[A\n",
      " 15%|█▍        | 60723/414113 [00:14<01:19, 4445.95it/s]\u001b[A\n",
      " 15%|█▍        | 61168/414113 [00:14<01:19, 4412.88it/s]\u001b[A\n",
      " 15%|█▍        | 61610/414113 [00:14<01:20, 4397.15it/s]\u001b[A\n",
      " 15%|█▍        | 62050/414113 [00:14<01:20, 4380.00it/s]\u001b[A\n",
      " 15%|█▌        | 62489/414113 [00:14<01:20, 4359.35it/s]\u001b[A\n",
      " 15%|█▌        | 62943/414113 [00:14<01:19, 4411.51it/s]\u001b[A\n",
      " 15%|█▌        | 63385/414113 [00:14<01:20, 4381.81it/s]\u001b[A\n",
      " 15%|█▌        | 63834/414113 [00:14<01:19, 4413.17it/s]\u001b[A\n",
      " 16%|█▌        | 64279/414113 [00:14<01:19, 4423.42it/s]\u001b[A\n",
      " 16%|█▌        | 64726/414113 [00:14<01:18, 4435.82it/s]\u001b[A\n",
      " 16%|█▌        | 65172/414113 [00:15<01:18, 4441.66it/s]\u001b[A\n",
      " 16%|█▌        | 65617/414113 [00:15<01:19, 4380.38it/s]\u001b[A\n",
      " 16%|█▌        | 66060/414113 [00:15<01:19, 4395.13it/s]\u001b[A\n",
      " 16%|█▌        | 66502/414113 [00:15<01:18, 4400.32it/s]\u001b[A\n",
      " 16%|█▌        | 66943/414113 [00:15<01:18, 4402.31it/s]\u001b[A\n",
      " 16%|█▋        | 67384/414113 [00:15<01:18, 4390.59it/s]\u001b[A\n",
      " 16%|█▋        | 67824/414113 [00:15<01:19, 4378.72it/s]\u001b[A\n",
      " 16%|█▋        | 68263/414113 [00:15<01:18, 4381.39it/s]\u001b[A\n",
      " 17%|█▋        | 68702/414113 [00:15<01:18, 4380.80it/s]\u001b[A\n",
      " 17%|█▋        | 69141/414113 [00:15<01:18, 4379.44it/s]\u001b[A\n",
      " 17%|█▋        | 69591/414113 [00:16<01:18, 4414.17it/s]\u001b[A\n",
      " 17%|█▋        | 70033/414113 [00:16<01:18, 4357.03it/s]\u001b[A\n",
      " 17%|█▋        | 70473/414113 [00:16<01:18, 4367.58it/s]\u001b[A\n",
      " 17%|█▋        | 70910/414113 [00:16<01:18, 4366.22it/s]\u001b[A\n",
      " 17%|█▋        | 71361/414113 [00:16<01:17, 4408.30it/s]\u001b[A\n",
      " 17%|█▋        | 71803/414113 [00:16<01:17, 4398.94it/s]\u001b[A\n",
      " 17%|█▋        | 72244/414113 [00:16<01:17, 4398.74it/s]\u001b[A\n",
      " 18%|█▊        | 72684/414113 [00:16<01:17, 4388.13it/s]\u001b[A\n",
      " 18%|█▊        | 73123/414113 [00:16<01:20, 4235.27it/s]\u001b[A\n",
      " 18%|█▊        | 73548/414113 [00:16<01:20, 4228.98it/s]\u001b[A\n",
      " 18%|█▊        | 73985/414113 [00:17<01:19, 4268.20it/s]\u001b[A\n",
      " 18%|█▊        | 74413/414113 [00:17<02:06, 2689.37it/s]\u001b[A\n",
      " 18%|█▊        | 74852/414113 [00:17<01:51, 3042.59it/s]\u001b[A\n",
      " 18%|█▊        | 75292/414113 [00:17<01:41, 3351.46it/s]\u001b[A\n",
      " 18%|█▊        | 75741/414113 [00:17<01:33, 3625.98it/s]\u001b[A\n",
      " 18%|█▊        | 76173/414113 [00:17<01:28, 3807.94it/s]\u001b[A\n",
      " 19%|█▊        | 76621/414113 [00:17<01:24, 3986.95it/s]\u001b[A\n",
      " 19%|█▊        | 77061/414113 [00:17<01:22, 4101.55it/s]\u001b[A\n",
      " 19%|█▊        | 77504/414113 [00:18<01:20, 4193.77it/s]\u001b[A\n",
      " 19%|█▉        | 77940/414113 [00:18<01:19, 4241.33it/s]\u001b[A\n",
      " 19%|█▉        | 78375/414113 [00:18<01:18, 4260.26it/s]\u001b[A\n",
      " 19%|█▉        | 78816/414113 [00:18<01:17, 4302.45it/s]\u001b[A\n",
      " 19%|█▉        | 79264/414113 [00:18<01:16, 4354.07it/s]\u001b[A\n",
      " 19%|█▉        | 79711/414113 [00:18<01:16, 4388.03it/s]\u001b[A\n",
      " 19%|█▉        | 80153/414113 [00:18<01:16, 4388.48it/s]\u001b[A\n",
      " 19%|█▉        | 80598/414113 [00:18<01:15, 4404.75it/s]\u001b[A\n",
      " 20%|█▉        | 81042/414113 [00:18<01:15, 4413.72it/s]\u001b[A\n",
      " 20%|█▉        | 81485/414113 [00:18<01:15, 4382.20it/s]\u001b[A\n",
      " 20%|█▉        | 81924/414113 [00:19<01:16, 4359.00it/s]\u001b[A\n",
      " 20%|█▉        | 82377/414113 [00:19<01:15, 4408.52it/s]\u001b[A\n",
      " 20%|█▉        | 82819/414113 [00:19<01:16, 4354.54it/s]\u001b[A\n",
      " 20%|██        | 83273/414113 [00:19<01:15, 4405.77it/s]\u001b[A\n",
      " 20%|██        | 83720/414113 [00:19<01:14, 4421.85it/s]\u001b[A\n",
      " 20%|██        | 84173/414113 [00:19<01:14, 4451.96it/s]\u001b[A\n",
      " 20%|██        | 84619/414113 [00:19<01:14, 4430.72it/s]\u001b[A\n",
      " 21%|██        | 85063/414113 [00:19<01:14, 4401.39it/s]\u001b[A\n",
      " 21%|██        | 85515/414113 [00:19<01:14, 4435.34it/s]\u001b[A\n",
      " 21%|██        | 85959/414113 [00:20<01:16, 4301.17it/s]\u001b[A\n",
      " 21%|██        | 86391/414113 [00:20<01:18, 4199.23it/s]\u001b[A\n",
      " 21%|██        | 86825/414113 [00:20<01:17, 4238.42it/s]\u001b[A\n",
      " 21%|██        | 87270/414113 [00:20<01:16, 4299.02it/s]\u001b[A\n",
      " 21%|██        | 87711/414113 [00:20<01:15, 4330.65it/s]\u001b[A\n",
      " 21%|██▏       | 88155/414113 [00:20<01:14, 4361.01it/s]\u001b[A\n",
      " 21%|██▏       | 88605/414113 [00:20<01:13, 4401.64it/s]\u001b[A\n",
      " 22%|██▏       | 89046/414113 [00:20<01:13, 4395.35it/s]\u001b[A\n",
      " 22%|██▏       | 89486/414113 [00:20<01:13, 4396.00it/s]\u001b[A\n",
      " 22%|██▏       | 89926/414113 [00:20<01:14, 4376.46it/s]\u001b[A\n",
      " 22%|██▏       | 90364/414113 [00:21<01:14, 4374.98it/s]\u001b[A\n",
      " 22%|██▏       | 90802/414113 [00:21<01:14, 4366.84it/s]\u001b[A\n",
      " 22%|██▏       | 91239/414113 [00:21<01:14, 4335.13it/s]\u001b[A\n",
      " 22%|██▏       | 91679/414113 [00:21<01:14, 4352.64it/s]\u001b[A\n",
      " 22%|██▏       | 92115/414113 [00:21<01:13, 4352.95it/s]\u001b[A\n",
      " 22%|██▏       | 92556/414113 [00:21<01:13, 4369.80it/s]\u001b[A\n",
      " 22%|██▏       | 93006/414113 [00:21<01:12, 4406.23it/s]\u001b[A\n",
      " 23%|██▎       | 93451/414113 [00:21<01:12, 4415.99it/s]\u001b[A\n",
      " 23%|██▎       | 93894/414113 [00:21<01:12, 4418.29it/s]\u001b[A\n",
      " 23%|██▎       | 94340/414113 [00:21<01:12, 4430.64it/s]\u001b[A\n",
      " 23%|██▎       | 94795/414113 [00:22<01:11, 4464.71it/s]\u001b[A\n",
      " 23%|██▎       | 95242/414113 [00:22<01:11, 4457.14it/s]\u001b[A\n",
      " 23%|██▎       | 95688/414113 [00:22<01:11, 4446.40it/s]\u001b[A\n",
      " 23%|██▎       | 96133/414113 [00:22<01:11, 4441.07it/s]\u001b[A\n",
      " 23%|██▎       | 96578/414113 [00:22<01:12, 4403.31it/s]\u001b[A\n",
      " 23%|██▎       | 97019/414113 [00:22<01:12, 4396.72it/s]\u001b[A\n",
      " 24%|██▎       | 97469/414113 [00:22<01:11, 4424.03it/s]\u001b[A\n",
      " 24%|██▎       | 97912/414113 [00:22<01:11, 4409.50it/s]\u001b[A\n",
      " 24%|██▍       | 98356/414113 [00:22<01:11, 4416.30it/s]\u001b[A\n",
      " 24%|██▍       | 98798/414113 [00:22<01:11, 4413.70it/s]\u001b[A\n",
      " 24%|██▍       | 99245/414113 [00:23<01:11, 4429.02it/s]\u001b[A\n",
      " 24%|██▍       | 99688/414113 [00:23<01:11, 4407.99it/s]\u001b[A\n",
      " 24%|██▍       | 100129/414113 [00:23<01:11, 4395.24it/s]\u001b[A\n",
      " 24%|██▍       | 100571/414113 [00:23<01:11, 4401.12it/s]\u001b[A\n",
      " 24%|██▍       | 101012/414113 [00:23<01:11, 4391.92it/s]\u001b[A\n",
      " 24%|██▍       | 101452/414113 [00:23<01:11, 4393.43it/s]\u001b[A\n",
      " 25%|██▍       | 101892/414113 [00:23<01:11, 4380.31it/s]\u001b[A\n",
      " 25%|██▍       | 102340/414113 [00:23<01:10, 4409.45it/s]\u001b[A\n",
      " 25%|██▍       | 102788/414113 [00:23<01:10, 4429.84it/s]\u001b[A\n",
      " 25%|██▍       | 103232/414113 [00:23<01:10, 4401.52it/s]\u001b[A\n",
      " 25%|██▌       | 103673/414113 [00:24<01:10, 4397.68it/s]\u001b[A\n",
      " 25%|██▌       | 104113/414113 [00:24<01:10, 4390.69it/s]\u001b[A\n",
      " 25%|██▌       | 104553/414113 [00:24<01:10, 4374.28it/s]\u001b[A\n",
      " 25%|██▌       | 104997/414113 [00:24<01:10, 4390.70it/s]\u001b[A\n",
      " 25%|██▌       | 105437/414113 [00:24<01:10, 4383.85it/s]\u001b[A\n",
      " 26%|██▌       | 105877/414113 [00:24<01:10, 4383.51it/s]\u001b[A\n",
      " 26%|██▌       | 106316/414113 [00:24<01:11, 4326.08it/s]\u001b[A\n",
      " 26%|██▌       | 106760/414113 [00:24<01:10, 4359.22it/s]\u001b[A\n",
      " 26%|██▌       | 107198/414113 [00:24<01:10, 4365.18it/s]\u001b[A\n",
      " 26%|██▌       | 107635/414113 [00:24<01:10, 4360.90it/s]\u001b[A\n",
      " 26%|██▌       | 108085/414113 [00:25<01:09, 4399.75it/s]\u001b[A\n",
      " 26%|██▌       | 108526/414113 [00:25<01:09, 4398.17it/s]\u001b[A\n",
      " 26%|██▋       | 108969/414113 [00:25<01:09, 4406.75it/s]\u001b[A\n",
      " 26%|██▋       | 109411/414113 [00:25<01:09, 4409.10it/s]\u001b[A\n",
      " 27%|██▋       | 109852/414113 [00:25<01:09, 4372.47it/s]\u001b[A\n",
      " 27%|██▋       | 110290/414113 [00:25<01:09, 4347.59it/s]\u001b[A\n",
      " 27%|██▋       | 110725/414113 [00:25<01:09, 4340.85it/s]\u001b[A\n",
      " 27%|██▋       | 111160/414113 [00:25<01:09, 4341.64it/s]\u001b[A\n",
      " 27%|██▋       | 111616/414113 [00:25<01:08, 4404.66it/s]\u001b[A\n",
      " 27%|██▋       | 112057/414113 [00:25<01:08, 4382.75it/s]\u001b[A\n",
      " 27%|██▋       | 112496/414113 [00:26<01:08, 4381.06it/s]\u001b[A\n",
      " 27%|██▋       | 112941/414113 [00:26<01:08, 4399.67it/s]\u001b[A\n",
      " 27%|██▋       | 113383/414113 [00:26<01:08, 4403.66it/s]\u001b[A\n",
      " 27%|██▋       | 113824/414113 [00:26<01:08, 4381.48it/s]\u001b[A\n",
      " 28%|██▊       | 114263/414113 [00:26<01:08, 4374.24it/s]\u001b[A\n",
      " 28%|██▊       | 114702/414113 [00:26<01:08, 4378.32it/s]\u001b[A\n",
      " 28%|██▊       | 115149/414113 [00:26<01:07, 4403.76it/s]\u001b[A\n",
      " 28%|██▊       | 115590/414113 [00:26<01:08, 4345.21it/s]\u001b[A\n",
      " 28%|██▊       | 116025/414113 [00:26<01:09, 4293.89it/s]\u001b[A\n",
      " 28%|██▊       | 116455/414113 [00:26<01:09, 4271.22it/s]\u001b[A\n",
      " 28%|██▊       | 116883/414113 [00:27<01:10, 4193.24it/s]\u001b[A\n",
      " 28%|██▊       | 117303/414113 [00:27<01:10, 4189.28it/s]\u001b[A\n",
      " 28%|██▊       | 117736/414113 [00:27<01:10, 4229.05it/s]\u001b[A\n",
      " 29%|██▊       | 118171/414113 [00:27<01:09, 4261.66it/s]\u001b[A\n",
      " 29%|██▊       | 118598/414113 [00:27<01:09, 4235.99it/s]\u001b[A\n",
      " 29%|██▊       | 119038/414113 [00:27<01:08, 4281.85it/s]\u001b[A\n",
      " 29%|██▉       | 119481/414113 [00:27<01:08, 4322.48it/s]\u001b[A\n",
      " 29%|██▉       | 119914/414113 [00:27<01:08, 4312.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 120369/414113 [00:27<01:07, 4380.10it/s]\u001b[A\n",
      " 29%|██▉       | 120816/414113 [00:27<01:06, 4405.28it/s]\u001b[A\n",
      " 29%|██▉       | 121262/414113 [00:28<01:06, 4420.26it/s]\u001b[A\n",
      " 29%|██▉       | 121713/414113 [00:28<01:05, 4445.83it/s]\u001b[A\n",
      " 29%|██▉       | 122158/414113 [00:28<01:05, 4423.97it/s]\u001b[A\n",
      " 30%|██▉       | 122609/414113 [00:28<01:05, 4448.03it/s]\u001b[A\n",
      " 30%|██▉       | 123054/414113 [00:28<01:05, 4425.79it/s]\u001b[A\n",
      " 30%|██▉       | 123513/414113 [00:28<01:04, 4472.70it/s]\u001b[A\n",
      " 30%|██▉       | 123961/414113 [00:28<01:04, 4467.34it/s]\u001b[A\n",
      " 30%|███       | 124408/414113 [00:28<01:05, 4395.86it/s]\u001b[A\n",
      " 30%|███       | 124848/414113 [00:28<01:05, 4391.82it/s]\u001b[A\n",
      " 30%|███       | 125293/414113 [00:29<01:05, 4407.54it/s]\u001b[A\n",
      " 30%|███       | 125734/414113 [00:29<01:05, 4387.60it/s]\u001b[A\n",
      " 30%|███       | 126173/414113 [00:29<01:05, 4385.89it/s]\u001b[A\n",
      " 31%|███       | 126612/414113 [00:29<01:05, 4375.44it/s]\u001b[A\n",
      " 31%|███       | 127065/414113 [00:29<01:04, 4419.83it/s]\u001b[A\n",
      " 31%|███       | 127508/414113 [00:29<01:04, 4415.51it/s]\u001b[A\n",
      " 31%|███       | 127957/414113 [00:29<01:04, 4435.13it/s]\u001b[A\n",
      " 31%|███       | 128401/414113 [00:29<01:04, 4412.13it/s]\u001b[A\n",
      " 31%|███       | 128843/414113 [00:29<01:04, 4390.85it/s]\u001b[A\n",
      " 31%|███       | 129283/414113 [00:29<01:04, 4384.79it/s]\u001b[A\n",
      " 31%|███▏      | 129735/414113 [00:30<01:04, 4422.76it/s]\u001b[A\n",
      " 31%|███▏      | 130181/414113 [00:30<01:04, 4432.93it/s]\u001b[A\n",
      " 32%|███▏      | 130626/414113 [00:30<01:03, 4437.59it/s]\u001b[A\n",
      " 32%|███▏      | 131070/414113 [00:30<01:04, 4420.72it/s]\u001b[A\n",
      " 32%|███▏      | 131514/414113 [00:30<01:03, 4424.27it/s]\u001b[A\n",
      " 32%|███▏      | 131961/414113 [00:30<01:03, 4435.13it/s]\u001b[A\n",
      " 32%|███▏      | 132405/414113 [00:30<01:03, 4408.88it/s]\u001b[A\n",
      " 32%|███▏      | 132846/414113 [00:30<01:03, 4402.03it/s]\u001b[A\n",
      " 32%|███▏      | 133287/414113 [00:30<01:04, 4343.41it/s]\u001b[A\n",
      " 32%|███▏      | 133723/414113 [00:30<01:04, 4345.65it/s]\u001b[A\n",
      " 32%|███▏      | 134161/414113 [00:31<01:04, 4352.86it/s]\u001b[A\n",
      " 33%|███▎      | 134597/414113 [00:31<01:04, 4340.39it/s]\u001b[A\n",
      " 33%|███▎      | 135032/414113 [00:31<01:04, 4334.54it/s]\u001b[A\n",
      " 33%|███▎      | 135490/414113 [00:31<01:03, 4405.19it/s]\u001b[A\n",
      " 33%|███▎      | 135936/414113 [00:31<01:02, 4419.40it/s]\u001b[A\n",
      " 33%|███▎      | 136382/414113 [00:31<01:02, 4430.85it/s]\u001b[A\n",
      " 33%|███▎      | 136826/414113 [00:31<01:03, 4367.19it/s]\u001b[A\n",
      " 33%|███▎      | 137266/414113 [00:31<01:03, 4375.35it/s]\u001b[A\n",
      " 33%|███▎      | 137704/414113 [00:31<01:03, 4375.44it/s]\u001b[A\n",
      " 33%|███▎      | 138155/414113 [00:31<01:02, 4412.64it/s]\u001b[A\n",
      " 33%|███▎      | 138597/414113 [00:32<01:03, 4372.42it/s]\u001b[A\n",
      " 34%|███▎      | 139035/414113 [00:32<01:02, 4368.78it/s]\u001b[A\n",
      " 34%|███▎      | 139480/414113 [00:32<01:02, 4390.91it/s]\u001b[A\n",
      " 34%|███▍      | 139924/414113 [00:32<01:02, 4403.74it/s]\u001b[A\n",
      " 34%|███▍      | 140375/414113 [00:32<01:01, 4434.71it/s]\u001b[A\n",
      " 34%|███▍      | 140824/414113 [00:32<01:01, 4450.84it/s]\u001b[A\n",
      " 34%|███▍      | 141270/414113 [00:32<01:01, 4423.97it/s]\u001b[A\n",
      " 34%|███▍      | 141713/414113 [00:32<01:02, 4390.58it/s]\u001b[A\n",
      " 34%|███▍      | 142177/414113 [00:32<01:00, 4461.26it/s]\u001b[A\n",
      " 34%|███▍      | 142632/414113 [00:32<01:00, 4486.56it/s]\u001b[A\n",
      " 35%|███▍      | 143081/414113 [00:33<01:00, 4486.51it/s]\u001b[A\n",
      " 35%|███▍      | 143530/414113 [00:33<01:00, 4482.10it/s]\u001b[A\n",
      " 35%|███▍      | 143979/414113 [00:33<01:00, 4428.65it/s]\u001b[A\n",
      " 35%|███▍      | 144423/414113 [00:33<01:01, 4412.18it/s]\u001b[A\n",
      " 35%|███▍      | 144873/414113 [00:33<01:00, 4436.43it/s]\u001b[A\n",
      " 35%|███▌      | 145321/414113 [00:33<01:00, 4447.04it/s]\u001b[A\n",
      " 35%|███▌      | 145772/414113 [00:33<01:00, 4465.04it/s]\u001b[A\n",
      " 35%|███▌      | 146219/414113 [00:33<01:00, 4394.08it/s]\u001b[A\n",
      " 35%|███▌      | 146659/414113 [00:33<01:01, 4375.02it/s]\u001b[A\n",
      " 36%|███▌      | 147114/414113 [00:33<01:00, 4424.51it/s]\u001b[A\n",
      " 36%|███▌      | 147557/414113 [00:34<01:00, 4408.09it/s]\u001b[A\n",
      " 36%|███▌      | 147999/414113 [00:34<01:00, 4408.86it/s]\u001b[A\n",
      " 36%|███▌      | 148441/414113 [00:34<01:00, 4361.09it/s]\u001b[A\n",
      " 36%|███▌      | 148897/414113 [00:34<01:00, 4418.80it/s]\u001b[A\n",
      " 36%|███▌      | 149340/414113 [00:34<01:00, 4396.11it/s]\u001b[A\n",
      " 36%|███▌      | 149780/414113 [00:34<01:07, 3933.98it/s]\u001b[A\n",
      " 36%|███▋      | 150223/414113 [00:34<01:04, 4069.87it/s]\u001b[A\n",
      " 36%|███▋      | 150661/414113 [00:34<01:03, 4157.71it/s]\u001b[A\n",
      " 36%|███▋      | 151109/414113 [00:34<01:01, 4246.84it/s]\u001b[A\n",
      " 37%|███▋      | 151559/414113 [00:34<01:00, 4317.08it/s]\u001b[A\n",
      " 37%|███▋      | 151995/414113 [00:35<01:08, 3835.14it/s]\u001b[A\n",
      " 37%|███▋      | 152439/414113 [00:35<01:05, 3998.04it/s]\u001b[A\n",
      " 37%|███▋      | 152891/414113 [00:35<01:03, 4141.02it/s]\u001b[A\n",
      " 37%|███▋      | 153351/414113 [00:35<01:01, 4267.05it/s]\u001b[A\n",
      " 37%|███▋      | 153801/414113 [00:35<01:00, 4332.27it/s]\u001b[A\n",
      " 37%|███▋      | 154264/414113 [00:35<00:58, 4414.69it/s]\u001b[A\n",
      " 37%|███▋      | 154713/414113 [00:35<00:58, 4434.67it/s]\u001b[A\n",
      " 37%|███▋      | 155161/414113 [00:35<00:58, 4448.11it/s]\u001b[A\n",
      " 38%|███▊      | 155608/414113 [00:35<00:58, 4435.99it/s]\u001b[A\n",
      " 38%|███▊      | 156060/414113 [00:36<00:57, 4458.37it/s]\u001b[A\n",
      " 38%|███▊      | 156507/414113 [00:36<00:58, 4434.74it/s]\u001b[A\n",
      " 38%|███▊      | 156952/414113 [00:36<00:58, 4413.68it/s]\u001b[A\n",
      " 38%|███▊      | 157403/414113 [00:36<00:57, 4440.94it/s]\u001b[A\n",
      " 38%|███▊      | 157848/414113 [00:36<00:58, 4386.29it/s]\u001b[A\n",
      " 38%|███▊      | 158305/414113 [00:36<00:57, 4439.17it/s]\u001b[A\n",
      " 38%|███▊      | 158764/414113 [00:36<00:56, 4481.35it/s]\u001b[A\n",
      " 38%|███▊      | 159220/414113 [00:36<00:56, 4503.78it/s]\u001b[A\n",
      " 39%|███▊      | 159671/414113 [00:36<00:56, 4488.45it/s]\u001b[A\n",
      " 39%|███▊      | 160128/414113 [00:36<00:56, 4512.24it/s]\u001b[A\n",
      " 39%|███▉      | 160580/414113 [00:37<00:56, 4505.42it/s]\u001b[A\n",
      " 39%|███▉      | 161031/414113 [00:37<00:56, 4498.75it/s]\u001b[A\n",
      " 39%|███▉      | 161481/414113 [00:37<00:56, 4498.85it/s]\u001b[A\n",
      " 39%|███▉      | 161931/414113 [00:37<00:57, 4422.24it/s]\u001b[A\n",
      " 39%|███▉      | 162401/414113 [00:37<00:55, 4501.93it/s]\u001b[A\n",
      " 39%|███▉      | 162852/414113 [00:37<00:55, 4498.40it/s]\u001b[A\n",
      " 39%|███▉      | 163303/414113 [00:37<00:56, 4471.27it/s]\u001b[A\n",
      " 40%|███▉      | 163751/414113 [00:37<00:56, 4458.10it/s]\u001b[A\n",
      " 40%|███▉      | 164198/414113 [00:37<00:56, 4441.23it/s]\u001b[A\n",
      " 40%|███▉      | 164643/414113 [00:37<00:56, 4405.95it/s]\u001b[A\n",
      " 40%|███▉      | 165097/414113 [00:38<00:56, 4444.58it/s]\u001b[A\n",
      " 40%|███▉      | 165542/414113 [00:38<00:56, 4383.42it/s]\u001b[A\n",
      " 40%|████      | 165981/414113 [00:38<00:57, 4320.72it/s]\u001b[A\n",
      " 40%|████      | 166414/414113 [00:38<00:57, 4291.86it/s]\u001b[A\n",
      " 40%|████      | 166844/414113 [00:38<00:57, 4265.25it/s]\u001b[A\n",
      " 40%|████      | 167275/414113 [00:38<00:57, 4278.03it/s]\u001b[A\n",
      " 41%|████      | 167716/414113 [00:38<00:57, 4315.64it/s]\u001b[A\n",
      " 41%|████      | 168159/414113 [00:38<00:56, 4347.46it/s]\u001b[A\n",
      " 41%|████      | 168602/414113 [00:38<00:56, 4370.30it/s]\u001b[A\n",
      " 41%|████      | 169043/414113 [00:38<00:55, 4380.11it/s]\u001b[A\n",
      " 41%|████      | 169488/414113 [00:39<00:55, 4399.57it/s]\u001b[A\n",
      " 41%|████      | 169929/414113 [00:39<00:55, 4401.21it/s]\u001b[A\n",
      " 41%|████      | 170370/414113 [00:39<00:55, 4401.48it/s]\u001b[A\n",
      " 41%|████      | 170811/414113 [00:39<00:55, 4392.76it/s]\u001b[A\n",
      " 41%|████▏     | 171252/414113 [00:39<00:55, 4396.54it/s]\u001b[A\n",
      " 41%|████▏     | 171692/414113 [00:39<00:55, 4352.62it/s]\u001b[A\n",
      " 42%|████▏     | 172144/414113 [00:39<00:54, 4399.92it/s]\u001b[A\n",
      " 42%|████▏     | 172585/414113 [00:39<00:57, 4232.24it/s]\u001b[A\n",
      " 42%|████▏     | 173025/414113 [00:39<00:56, 4280.28it/s]\u001b[A\n",
      " 42%|████▏     | 173455/414113 [00:40<00:56, 4276.91it/s]\u001b[A\n",
      " 42%|████▏     | 173884/414113 [00:40<00:56, 4224.13it/s]\u001b[A\n",
      " 42%|████▏     | 174308/414113 [00:40<00:57, 4167.39it/s]\u001b[A\n",
      " 42%|████▏     | 174726/414113 [00:40<00:57, 4141.66it/s]\u001b[A\n",
      " 42%|████▏     | 175141/414113 [00:40<01:35, 2490.03it/s]\u001b[A\n",
      " 42%|████▏     | 175563/414113 [00:40<01:24, 2838.94it/s]\u001b[A\n",
      " 43%|████▎     | 175999/414113 [00:40<01:15, 3170.53it/s]\u001b[A\n",
      " 43%|████▎     | 176430/414113 [00:40<01:09, 3442.40it/s]\u001b[A\n",
      " 43%|████▎     | 176864/414113 [00:41<01:04, 3668.64it/s]\u001b[A\n",
      " 43%|████▎     | 177300/414113 [00:41<01:01, 3850.28it/s]\u001b[A\n",
      " 43%|████▎     | 177744/414113 [00:41<00:58, 4007.71it/s]\u001b[A\n",
      " 43%|████▎     | 178176/414113 [00:41<00:57, 4094.34it/s]\u001b[A\n",
      " 43%|████▎     | 178616/414113 [00:41<00:56, 4180.84it/s]\u001b[A\n",
      " 43%|████▎     | 179054/414113 [00:41<00:55, 4236.13it/s]\u001b[A\n",
      " 43%|████▎     | 179510/414113 [00:41<00:54, 4326.45it/s]\u001b[A\n",
      " 43%|████▎     | 179950/414113 [00:41<00:54, 4335.87it/s]\u001b[A\n",
      " 44%|████▎     | 180389/414113 [00:41<00:53, 4349.07it/s]\u001b[A\n",
      " 44%|████▎     | 180828/414113 [00:41<00:53, 4342.95it/s]\u001b[A\n",
      " 44%|████▍     | 181270/414113 [00:42<00:53, 4363.77it/s]\u001b[A\n",
      " 44%|████▍     | 181708/414113 [00:42<00:54, 4295.72it/s]\u001b[A\n",
      " 44%|████▍     | 182139/414113 [00:42<00:54, 4247.45it/s]\u001b[A\n",
      " 44%|████▍     | 182565/414113 [00:42<00:54, 4232.46it/s]\u001b[A\n",
      " 44%|████▍     | 182990/414113 [00:42<00:54, 4209.42it/s]\u001b[A\n",
      " 44%|████▍     | 183412/414113 [00:42<00:55, 4143.94it/s]\u001b[A\n",
      " 44%|████▍     | 183828/414113 [00:42<00:55, 4128.36it/s]\u001b[A\n",
      " 44%|████▍     | 184242/414113 [00:42<00:55, 4131.79it/s]\u001b[A\n",
      " 45%|████▍     | 184656/414113 [00:42<00:57, 4014.93it/s]\u001b[A\n",
      " 45%|████▍     | 185082/414113 [00:42<00:56, 4083.65it/s]\u001b[A\n",
      " 45%|████▍     | 185504/414113 [00:43<00:55, 4122.63it/s]\u001b[A\n",
      " 45%|████▍     | 185920/414113 [00:43<00:55, 4133.50it/s]\u001b[A\n",
      " 45%|████▍     | 186347/414113 [00:43<00:54, 4173.08it/s]\u001b[A\n",
      " 45%|████▌     | 186792/414113 [00:43<00:53, 4251.91it/s]\u001b[A\n",
      " 45%|████▌     | 187221/414113 [00:43<00:53, 4261.82it/s]\u001b[A\n",
      " 45%|████▌     | 187662/414113 [00:43<00:52, 4305.07it/s]\u001b[A\n",
      " 45%|████▌     | 188098/414113 [00:43<00:52, 4318.97it/s]\u001b[A\n",
      " 46%|████▌     | 188535/414113 [00:43<00:52, 4331.31it/s]\u001b[A\n",
      " 46%|████▌     | 188969/414113 [00:43<00:52, 4322.69it/s]\u001b[A\n",
      " 46%|████▌     | 189418/414113 [00:43<00:51, 4370.81it/s]\u001b[A\n",
      " 46%|████▌     | 189856/414113 [00:44<00:51, 4368.79it/s]\u001b[A\n",
      " 46%|████▌     | 190295/414113 [00:44<00:51, 4373.18it/s]\u001b[A\n",
      " 46%|████▌     | 190733/414113 [00:44<00:51, 4369.82it/s]\u001b[A\n",
      " 46%|████▌     | 191172/414113 [00:44<00:50, 4373.57it/s]\u001b[A\n",
      " 46%|████▋     | 191610/414113 [00:44<00:50, 4370.27it/s]\u001b[A\n",
      " 46%|████▋     | 192048/414113 [00:44<00:51, 4348.93it/s]\u001b[A\n",
      " 46%|████▋     | 192496/414113 [00:44<00:50, 4386.79it/s]\u001b[A\n",
      " 47%|████▋     | 192935/414113 [00:44<00:50, 4377.02it/s]\u001b[A\n",
      " 47%|████▋     | 193373/414113 [00:44<00:50, 4345.11it/s]\u001b[A\n",
      " 47%|████▋     | 193823/414113 [00:44<00:50, 4389.77it/s]\u001b[A\n",
      " 47%|████▋     | 194263/414113 [00:45<00:50, 4370.55it/s]\u001b[A\n",
      " 47%|████▋     | 194701/414113 [00:45<00:50, 4347.93it/s]\u001b[A\n",
      " 47%|████▋     | 195136/414113 [00:45<00:50, 4346.99it/s]\u001b[A\n",
      " 47%|████▋     | 195579/414113 [00:45<00:50, 4370.42it/s]\u001b[A\n",
      " 47%|████▋     | 196017/414113 [00:45<00:49, 4369.43it/s]\u001b[A\n",
      " 47%|████▋     | 196466/414113 [00:45<00:49, 4402.61it/s]\u001b[A\n",
      " 48%|████▊     | 196907/414113 [00:45<00:49, 4389.75it/s]\u001b[A\n",
      " 48%|████▊     | 197347/414113 [00:45<00:49, 4379.58it/s]\u001b[A\n",
      " 48%|████▊     | 197800/414113 [00:45<00:48, 4421.13it/s]\u001b[A\n",
      " 48%|████▊     | 198243/414113 [00:45<00:48, 4413.49it/s]\u001b[A\n",
      " 48%|████▊     | 198685/414113 [00:46<00:48, 4397.77it/s]\u001b[A\n",
      " 48%|████▊     | 199125/414113 [00:46<00:49, 4361.96it/s]\u001b[A\n",
      " 48%|████▊     | 199562/414113 [00:46<00:49, 4314.65it/s]\u001b[A\n",
      " 48%|████▊     | 199995/414113 [00:46<00:49, 4317.87it/s]\u001b[A\n",
      " 48%|████▊     | 200447/414113 [00:46<00:48, 4375.08it/s]\u001b[A\n",
      " 49%|████▊     | 200895/414113 [00:46<00:48, 4403.41it/s]\u001b[A\n",
      " 49%|████▊     | 201350/414113 [00:46<00:47, 4445.84it/s]\u001b[A\n",
      " 49%|████▊     | 201809/414113 [00:46<00:47, 4486.77it/s]\u001b[A\n",
      " 49%|████▉     | 202262/414113 [00:46<00:47, 4496.79it/s]\u001b[A\n",
      " 49%|████▉     | 202716/414113 [00:46<00:46, 4507.42it/s]\u001b[A\n",
      " 49%|████▉     | 203184/414113 [00:47<00:46, 4557.17it/s]\u001b[A\n",
      " 49%|████▉     | 203640/414113 [00:47<00:46, 4554.18it/s]\u001b[A\n",
      " 49%|████▉     | 204096/414113 [00:47<00:46, 4522.25it/s]\u001b[A\n",
      " 49%|████▉     | 204549/414113 [00:47<00:46, 4501.91it/s]\u001b[A\n",
      " 50%|████▉     | 205000/414113 [00:47<00:46, 4494.28it/s]\u001b[A\n",
      " 50%|████▉     | 205450/414113 [00:47<00:47, 4437.33it/s]\u001b[A\n",
      " 50%|████▉     | 205894/414113 [00:47<00:48, 4252.98it/s]\u001b[A\n",
      " 50%|████▉     | 206322/414113 [00:47<00:48, 4258.62it/s]\u001b[A\n",
      " 50%|████▉     | 206756/414113 [00:47<00:48, 4281.26it/s]\u001b[A\n",
      " 50%|█████     | 207197/414113 [00:48<00:47, 4316.49it/s]\u001b[A\n",
      " 50%|█████     | 207630/414113 [00:48<00:48, 4295.12it/s]\u001b[A\n",
      " 50%|█████     | 208061/414113 [00:48<00:48, 4278.65it/s]\u001b[A\n",
      " 50%|█████     | 208490/414113 [00:48<00:48, 4270.29it/s]\u001b[A\n",
      " 50%|█████     | 208927/414113 [00:48<00:47, 4297.60it/s]\u001b[A\n",
      " 51%|█████     | 209357/414113 [00:48<00:48, 4255.25it/s]\u001b[A\n",
      " 51%|█████     | 209800/414113 [00:48<00:47, 4305.57it/s]\u001b[A\n",
      " 51%|█████     | 210242/414113 [00:48<00:46, 4338.14it/s]\u001b[A\n",
      " 51%|█████     | 210694/414113 [00:48<00:46, 4389.26it/s]\u001b[A\n",
      " 51%|█████     | 211134/414113 [00:48<00:46, 4367.42it/s]\u001b[A\n",
      " 51%|█████     | 211587/414113 [00:49<00:45, 4412.13it/s]\u001b[A\n",
      " 51%|█████     | 212029/414113 [00:49<00:45, 4407.07it/s]\u001b[A\n",
      " 51%|█████▏    | 212474/414113 [00:49<00:45, 4417.89it/s]\u001b[A\n",
      " 51%|█████▏    | 212916/414113 [00:49<00:45, 4400.59it/s]\u001b[A\n",
      " 52%|█████▏    | 213361/414113 [00:49<00:45, 4414.60it/s]\u001b[A\n",
      " 52%|█████▏    | 213812/414113 [00:49<00:45, 4441.78it/s]\u001b[A\n",
      " 52%|█████▏    | 214257/414113 [00:49<00:44, 4442.92it/s]\u001b[A\n",
      " 52%|█████▏    | 214702/414113 [00:49<00:45, 4427.47it/s]\u001b[A\n",
      " 52%|█████▏    | 215146/414113 [00:49<00:44, 4429.27it/s]\u001b[A\n",
      " 52%|█████▏    | 215589/414113 [00:49<00:45, 4397.64it/s]\u001b[A\n",
      " 52%|█████▏    | 216038/414113 [00:50<00:44, 4424.90it/s]\u001b[A\n",
      " 52%|█████▏    | 216481/414113 [00:50<00:45, 4354.05it/s]\u001b[A\n",
      " 52%|█████▏    | 216928/414113 [00:50<00:44, 4387.07it/s]\u001b[A\n",
      " 52%|█████▏    | 217377/414113 [00:50<00:44, 4415.53it/s]\u001b[A\n",
      " 53%|█████▎    | 217833/414113 [00:50<00:44, 4455.59it/s]\u001b[A\n",
      " 53%|█████▎    | 218285/414113 [00:50<00:43, 4472.62it/s]\u001b[A\n",
      " 53%|█████▎    | 218742/414113 [00:50<00:43, 4499.41it/s]\u001b[A\n",
      " 53%|█████▎    | 219195/414113 [00:50<00:43, 4507.95it/s]\u001b[A\n",
      " 53%|█████▎    | 219648/414113 [00:50<00:43, 4512.69it/s]\u001b[A\n",
      " 53%|█████▎    | 220100/414113 [00:50<00:43, 4466.66it/s]\u001b[A\n",
      " 53%|█████▎    | 220547/414113 [00:51<00:43, 4462.87it/s]\u001b[A\n",
      " 53%|█████▎    | 220994/414113 [00:51<00:43, 4450.94it/s]\u001b[A\n",
      " 53%|█████▎    | 221440/414113 [00:51<00:43, 4380.03it/s]\u001b[A\n",
      " 54%|█████▎    | 221891/414113 [00:51<00:43, 4415.95it/s]\u001b[A\n",
      " 54%|█████▎    | 222343/414113 [00:51<00:43, 4445.73it/s]\u001b[A\n",
      " 54%|█████▍    | 222800/414113 [00:51<00:42, 4480.18it/s]\u001b[A\n",
      " 54%|█████▍    | 223259/414113 [00:51<00:42, 4509.64it/s]\u001b[A\n",
      " 54%|█████▍    | 223711/414113 [00:51<00:42, 4503.54it/s]\u001b[A\n",
      " 54%|█████▍    | 224162/414113 [00:51<00:42, 4502.79it/s]\u001b[A\n",
      " 54%|█████▍    | 224613/414113 [00:51<00:42, 4484.09it/s]\u001b[A\n",
      " 54%|█████▍    | 225062/414113 [00:52<00:42, 4448.56it/s]\u001b[A\n",
      " 54%|█████▍    | 225507/414113 [00:52<00:42, 4405.69it/s]\u001b[A\n",
      " 55%|█████▍    | 225948/414113 [00:52<00:42, 4390.90it/s]\u001b[A\n",
      " 55%|█████▍    | 226406/414113 [00:52<00:42, 4445.30it/s]\u001b[A\n",
      " 55%|█████▍    | 226865/414113 [00:52<00:41, 4485.58it/s]\u001b[A\n",
      " 55%|█████▍    | 227314/414113 [00:52<00:42, 4419.81it/s]\u001b[A\n",
      " 55%|█████▍    | 227757/414113 [00:52<00:42, 4369.53it/s]\u001b[A\n",
      " 55%|█████▌    | 228195/414113 [00:52<00:42, 4368.92it/s]\u001b[A\n",
      " 55%|█████▌    | 228633/414113 [00:52<00:42, 4331.53it/s]\u001b[A\n",
      " 55%|█████▌    | 229067/414113 [00:52<00:42, 4309.24it/s]\u001b[A\n",
      " 55%|█████▌    | 229499/414113 [00:53<00:43, 4263.39it/s]\u001b[A\n",
      " 56%|█████▌    | 229926/414113 [00:53<00:43, 4224.24it/s]\u001b[A\n",
      " 56%|█████▌    | 230349/414113 [00:53<00:43, 4220.99it/s]\u001b[A\n",
      " 56%|█████▌    | 230791/414113 [00:53<00:42, 4277.27it/s]\u001b[A\n",
      " 56%|█████▌    | 231229/414113 [00:53<00:42, 4307.26it/s]\u001b[A\n",
      " 56%|█████▌    | 231672/414113 [00:53<00:42, 4340.65it/s]\u001b[A\n",
      " 56%|█████▌    | 232108/414113 [00:53<00:41, 4345.12it/s]\u001b[A\n",
      " 56%|█████▌    | 232549/414113 [00:53<00:41, 4362.68it/s]\u001b[A\n",
      " 56%|█████▋    | 232986/414113 [00:53<00:41, 4352.64it/s]\u001b[A\n",
      " 56%|█████▋    | 233422/414113 [00:53<00:41, 4334.98it/s]\u001b[A\n",
      " 56%|█████▋    | 233863/414113 [00:54<00:41, 4354.02it/s]\u001b[A\n",
      " 57%|█████▋    | 234305/414113 [00:54<00:41, 4371.57it/s]\u001b[A\n",
      " 57%|█████▋    | 234743/414113 [00:54<00:41, 4365.56it/s]\u001b[A\n",
      " 57%|█████▋    | 235180/414113 [00:54<00:41, 4361.98it/s]\u001b[A\n",
      " 57%|█████▋    | 235624/414113 [00:54<00:40, 4384.13it/s]\u001b[A\n",
      " 57%|█████▋    | 236076/414113 [00:54<00:40, 4420.13it/s]\u001b[A\n",
      " 57%|█████▋    | 236519/414113 [00:54<00:40, 4404.27it/s]\u001b[A\n",
      " 57%|█████▋    | 236960/414113 [00:54<00:40, 4404.83it/s]\u001b[A\n",
      " 57%|█████▋    | 237401/414113 [00:54<00:40, 4352.60it/s]\u001b[A\n",
      " 57%|█████▋    | 237838/414113 [00:54<00:40, 4355.20it/s]\u001b[A\n",
      " 58%|█████▊    | 238274/414113 [00:55<00:40, 4332.10it/s]\u001b[A\n",
      " 58%|█████▊    | 238716/414113 [00:55<00:40, 4355.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 239152/414113 [00:55<00:40, 4337.48it/s]\u001b[A\n",
      " 58%|█████▊    | 239587/414113 [00:55<00:40, 4340.81it/s]\u001b[A\n",
      " 58%|█████▊    | 240026/414113 [00:55<00:39, 4354.95it/s]\u001b[A\n",
      " 58%|█████▊    | 240462/414113 [00:55<00:40, 4256.29it/s]\u001b[A\n",
      " 58%|█████▊    | 240903/414113 [00:55<00:40, 4300.20it/s]\u001b[A\n",
      " 58%|█████▊    | 241344/414113 [00:55<00:39, 4331.21it/s]\u001b[A\n",
      " 58%|█████▊    | 241778/414113 [00:55<00:39, 4328.68it/s]\u001b[A\n",
      " 58%|█████▊    | 242214/414113 [00:56<00:39, 4337.86it/s]\u001b[A\n",
      " 59%|█████▊    | 242650/414113 [00:56<00:39, 4343.01it/s]\u001b[A\n",
      " 59%|█████▊    | 243085/414113 [00:56<00:39, 4332.24it/s]\u001b[A\n",
      " 59%|█████▉    | 243519/414113 [00:56<00:40, 4189.94it/s]\u001b[A\n",
      " 59%|█████▉    | 243955/414113 [00:56<00:40, 4238.48it/s]\u001b[A\n",
      " 59%|█████▉    | 244380/414113 [00:56<00:40, 4207.51it/s]\u001b[A\n",
      " 59%|█████▉    | 244815/414113 [00:56<00:39, 4247.89it/s]\u001b[A\n",
      " 59%|█████▉    | 245253/414113 [00:56<00:39, 4285.07it/s]\u001b[A\n",
      " 59%|█████▉    | 245682/414113 [00:56<00:39, 4278.14it/s]\u001b[A\n",
      " 59%|█████▉    | 246111/414113 [00:56<00:40, 4179.38it/s]\u001b[A\n",
      " 60%|█████▉    | 246540/414113 [00:57<00:39, 4209.39it/s]\u001b[A\n",
      " 60%|█████▉    | 246972/414113 [00:57<00:39, 4240.73it/s]\u001b[A\n",
      " 60%|█████▉    | 247413/414113 [00:57<00:38, 4289.64it/s]\u001b[A\n",
      " 60%|█████▉    | 247843/414113 [00:57<00:38, 4285.76it/s]\u001b[A\n",
      " 60%|█████▉    | 248272/414113 [00:57<00:38, 4270.39it/s]\u001b[A\n",
      " 60%|██████    | 248704/414113 [00:57<00:38, 4282.88it/s]\u001b[A\n",
      " 60%|██████    | 249145/414113 [00:57<00:38, 4320.10it/s]\u001b[A\n",
      " 60%|██████    | 249583/414113 [00:57<00:37, 4336.03it/s]\u001b[A\n",
      " 60%|██████    | 250028/414113 [00:57<00:37, 4367.18it/s]\u001b[A\n",
      " 60%|██████    | 250465/414113 [00:57<00:37, 4312.91it/s]\u001b[A\n",
      " 61%|██████    | 250902/414113 [00:58<00:37, 4327.71it/s]\u001b[A\n",
      " 61%|██████    | 251341/414113 [00:58<00:37, 4345.27it/s]\u001b[A\n",
      " 61%|██████    | 251784/414113 [00:58<00:37, 4368.30it/s]\u001b[A\n",
      " 61%|██████    | 252222/414113 [00:58<00:37, 4369.20it/s]\u001b[A\n",
      " 61%|██████    | 252661/414113 [00:58<00:36, 4374.64it/s]\u001b[A\n",
      " 61%|██████    | 253099/414113 [00:58<00:37, 4350.49it/s]\u001b[A\n",
      " 61%|██████    | 253541/414113 [00:58<00:36, 4369.99it/s]\u001b[A\n",
      " 61%|██████▏   | 253979/414113 [00:58<00:36, 4354.98it/s]\u001b[A\n",
      " 61%|██████▏   | 254415/414113 [00:58<00:37, 4243.79it/s]\u001b[A\n",
      " 62%|██████▏   | 254860/414113 [00:58<00:37, 4303.02it/s]\u001b[A\n",
      " 62%|██████▏   | 255317/414113 [00:59<00:36, 4379.04it/s]\u001b[A\n",
      " 62%|██████▏   | 255756/414113 [00:59<00:36, 4366.65it/s]\u001b[A\n",
      " 62%|██████▏   | 256199/414113 [00:59<00:36, 4385.27it/s]\u001b[A\n",
      " 62%|██████▏   | 256642/414113 [00:59<00:35, 4395.96it/s]\u001b[A\n",
      " 62%|██████▏   | 257102/414113 [00:59<00:35, 4454.65it/s]\u001b[A\n",
      " 62%|██████▏   | 257548/414113 [00:59<00:35, 4430.74it/s]\u001b[A\n",
      " 62%|██████▏   | 258007/414113 [00:59<00:34, 4476.91it/s]\u001b[A\n",
      " 62%|██████▏   | 258456/414113 [00:59<00:35, 4392.35it/s]\u001b[A\n",
      " 63%|██████▎   | 258896/414113 [00:59<00:35, 4389.06it/s]\u001b[A\n",
      " 63%|██████▎   | 259338/414113 [00:59<00:35, 4395.85it/s]\u001b[A\n",
      " 63%|██████▎   | 259792/414113 [01:00<00:34, 4435.14it/s]\u001b[A\n",
      " 63%|██████▎   | 260240/414113 [01:00<00:34, 4448.38it/s]\u001b[A\n",
      " 63%|██████▎   | 260686/414113 [01:00<00:34, 4444.88it/s]\u001b[A\n",
      " 63%|██████▎   | 261131/414113 [01:00<00:34, 4377.41it/s]\u001b[A\n",
      " 63%|██████▎   | 261570/414113 [01:00<00:34, 4378.63it/s]\u001b[A\n",
      " 63%|██████▎   | 262009/414113 [01:00<00:34, 4358.48it/s]\u001b[A\n",
      " 63%|██████▎   | 262450/414113 [01:00<00:34, 4373.38it/s]\u001b[A\n",
      " 63%|██████▎   | 262888/414113 [01:00<00:35, 4309.66it/s]\u001b[A\n",
      " 64%|██████▎   | 263320/414113 [01:00<00:35, 4299.57it/s]\u001b[A\n",
      " 64%|██████▎   | 263751/414113 [01:00<00:34, 4296.48it/s]\u001b[A\n",
      " 64%|██████▍   | 264182/414113 [01:01<00:34, 4299.32it/s]\u001b[A\n",
      " 64%|██████▍   | 264613/414113 [01:01<00:34, 4300.42it/s]\u001b[A\n",
      " 64%|██████▍   | 265044/414113 [01:01<00:34, 4287.83it/s]\u001b[A\n",
      " 64%|██████▍   | 265481/414113 [01:01<00:34, 4309.95it/s]\u001b[A\n",
      " 64%|██████▍   | 265913/414113 [01:01<00:34, 4306.72it/s]\u001b[A\n",
      " 64%|██████▍   | 266347/414113 [01:01<00:34, 4316.13it/s]\u001b[A\n",
      " 64%|██████▍   | 266779/414113 [01:01<00:34, 4281.50it/s]\u001b[A\n",
      " 65%|██████▍   | 267208/414113 [01:01<00:34, 4254.37it/s]\u001b[A\n",
      " 65%|██████▍   | 267641/414113 [01:01<00:34, 4276.28it/s]\u001b[A\n",
      " 65%|██████▍   | 268072/414113 [01:01<00:34, 4285.43it/s]\u001b[A\n",
      " 65%|██████▍   | 268501/414113 [01:02<00:34, 4233.59it/s]\u001b[A\n",
      " 65%|██████▍   | 268925/414113 [01:02<00:34, 4221.23it/s]\u001b[A\n",
      " 65%|██████▌   | 269348/414113 [01:02<00:34, 4213.88it/s]\u001b[A\n",
      " 65%|██████▌   | 269770/414113 [01:02<00:34, 4214.03it/s]\u001b[A\n",
      " 65%|██████▌   | 270193/414113 [01:02<00:34, 4216.77it/s]\u001b[A\n",
      " 65%|██████▌   | 270626/414113 [01:02<00:33, 4249.35it/s]\u001b[A\n",
      " 65%|██████▌   | 271068/414113 [01:02<00:33, 4297.87it/s]\u001b[A\n",
      " 66%|██████▌   | 271498/414113 [01:02<00:33, 4267.47it/s]\u001b[A\n",
      " 66%|██████▌   | 271925/414113 [01:02<00:33, 4223.92it/s]\u001b[A\n",
      " 66%|██████▌   | 272348/414113 [01:02<00:33, 4220.97it/s]\u001b[A\n",
      " 66%|██████▌   | 272771/414113 [01:03<00:33, 4217.77it/s]\u001b[A\n",
      " 66%|██████▌   | 273193/414113 [01:03<00:33, 4184.13it/s]\u001b[A\n",
      " 66%|██████▌   | 273612/414113 [01:03<00:33, 4181.83it/s]\u001b[A\n",
      " 66%|██████▌   | 274046/414113 [01:03<00:33, 4226.24it/s]\u001b[A\n",
      " 66%|██████▋   | 274469/414113 [01:03<00:33, 4212.50it/s]\u001b[A\n",
      " 66%|██████▋   | 274891/414113 [01:03<00:34, 4080.17it/s]\u001b[A\n",
      " 66%|██████▋   | 275320/414113 [01:03<00:33, 4139.40it/s]\u001b[A\n",
      " 67%|██████▋   | 275768/414113 [01:03<00:32, 4233.87it/s]\u001b[A\n",
      " 67%|██████▋   | 276224/414113 [01:03<00:31, 4325.37it/s]\u001b[A\n",
      " 67%|██████▋   | 276666/414113 [01:04<00:31, 4352.81it/s]\u001b[A\n",
      " 67%|██████▋   | 277103/414113 [01:04<00:31, 4344.26it/s]\u001b[A\n",
      " 67%|██████▋   | 277549/414113 [01:04<00:31, 4377.91it/s]\u001b[A\n",
      " 67%|██████▋   | 277995/414113 [01:04<00:30, 4401.70it/s]\u001b[A\n",
      " 67%|██████▋   | 278438/414113 [01:04<00:30, 4409.61it/s]\u001b[A\n",
      " 67%|██████▋   | 278884/414113 [01:04<00:30, 4423.69it/s]\u001b[A\n",
      " 67%|██████▋   | 279329/414113 [01:04<00:30, 4428.74it/s]\u001b[A\n",
      " 68%|██████▊   | 279773/414113 [01:04<00:30, 4372.68it/s]\u001b[A\n",
      " 68%|██████▊   | 280218/414113 [01:04<00:30, 4393.30it/s]\u001b[A\n",
      " 68%|██████▊   | 280663/414113 [01:04<00:30, 4409.59it/s]\u001b[A\n",
      " 68%|██████▊   | 281111/414113 [01:05<00:30, 4429.01it/s]\u001b[A\n",
      " 68%|██████▊   | 281556/414113 [01:05<00:29, 4432.65it/s]\u001b[A\n",
      " 68%|██████▊   | 282003/414113 [01:05<00:29, 4441.94it/s]\u001b[A\n",
      " 68%|██████▊   | 282452/414113 [01:05<00:29, 4455.55it/s]\u001b[A\n",
      " 68%|██████▊   | 282898/414113 [01:05<00:29, 4448.87it/s]\u001b[A\n",
      " 68%|██████▊   | 283343/414113 [01:05<00:29, 4440.35it/s]\u001b[A\n",
      " 69%|██████▊   | 283805/414113 [01:05<00:29, 4492.38it/s]\u001b[A\n",
      " 69%|██████▊   | 284255/414113 [01:05<00:29, 4475.72it/s]\u001b[A\n",
      " 69%|██████▉   | 284703/414113 [01:05<00:29, 4426.86it/s]\u001b[A\n",
      " 69%|██████▉   | 285150/414113 [01:05<00:29, 4439.01it/s]\u001b[A\n",
      " 69%|██████▉   | 285606/414113 [01:06<00:28, 4471.29it/s]\u001b[A\n",
      " 69%|██████▉   | 286054/414113 [01:06<00:28, 4462.20it/s]\u001b[A\n",
      " 69%|██████▉   | 286503/414113 [01:06<00:28, 4469.89it/s]\u001b[A\n",
      " 69%|██████▉   | 286951/414113 [01:06<00:28, 4463.88it/s]\u001b[A\n",
      " 69%|██████▉   | 287404/414113 [01:06<00:28, 4479.85it/s]\u001b[A\n",
      " 70%|██████▉   | 287853/414113 [01:06<00:28, 4449.51it/s]\u001b[A\n",
      " 70%|██████▉   | 288309/414113 [01:06<00:28, 4481.69it/s]\u001b[A\n",
      " 70%|██████▉   | 288758/414113 [01:06<00:27, 4479.68it/s]\u001b[A\n",
      " 70%|██████▉   | 289207/414113 [01:06<00:27, 4461.69it/s]\u001b[A\n",
      " 70%|██████▉   | 289655/414113 [01:06<00:27, 4464.92it/s]\u001b[A\n",
      " 70%|███████   | 290102/414113 [01:07<00:28, 4369.77it/s]\u001b[A\n",
      " 70%|███████   | 290557/414113 [01:07<00:27, 4420.08it/s]\u001b[A\n",
      " 70%|███████   | 291001/414113 [01:07<00:27, 4424.80it/s]\u001b[A\n",
      " 70%|███████   | 291444/414113 [01:07<00:28, 4379.14it/s]\u001b[A\n",
      " 70%|███████   | 291895/414113 [01:07<00:27, 4414.53it/s]\u001b[A\n",
      " 71%|███████   | 292345/414113 [01:07<00:27, 4438.91it/s]\u001b[A\n",
      " 71%|███████   | 292790/414113 [01:07<00:27, 4437.56it/s]\u001b[A\n",
      " 71%|███████   | 293234/414113 [01:07<00:27, 4422.55it/s]\u001b[A\n",
      " 71%|███████   | 293677/414113 [01:07<00:27, 4311.91it/s]\u001b[A\n",
      " 71%|███████   | 294109/414113 [01:07<00:28, 4279.68it/s]\u001b[A\n",
      " 71%|███████   | 294538/414113 [01:08<00:28, 4263.74it/s]\u001b[A\n",
      " 71%|███████   | 294965/414113 [01:08<00:28, 4209.45it/s]\u001b[A\n",
      " 71%|███████▏  | 295387/414113 [01:08<00:28, 4201.72it/s]\u001b[A\n",
      " 71%|███████▏  | 295817/414113 [01:08<00:27, 4229.51it/s]\u001b[A\n",
      " 72%|███████▏  | 296241/414113 [01:08<00:27, 4227.53it/s]\u001b[A\n",
      " 72%|███████▏  | 296676/414113 [01:08<00:27, 4261.10it/s]\u001b[A\n",
      " 72%|███████▏  | 297112/414113 [01:08<00:27, 4288.97it/s]\u001b[A\n",
      " 72%|███████▏  | 297551/414113 [01:08<00:27, 4316.72it/s]\u001b[A\n",
      " 72%|███████▏  | 297983/414113 [01:08<00:26, 4308.53it/s]\u001b[A\n",
      " 72%|███████▏  | 298414/414113 [01:08<00:26, 4304.26it/s]\u001b[A\n",
      " 72%|███████▏  | 298856/414113 [01:09<00:26, 4335.74it/s]\u001b[A\n",
      " 72%|███████▏  | 299290/414113 [01:09<00:26, 4330.56it/s]\u001b[A\n",
      " 72%|███████▏  | 299735/414113 [01:09<00:26, 4363.96it/s]\u001b[A\n",
      " 72%|███████▏  | 300185/414113 [01:09<00:25, 4403.31it/s]\u001b[A\n",
      " 73%|███████▎  | 300626/414113 [01:09<00:46, 2464.23it/s]\u001b[A\n",
      " 73%|███████▎  | 301070/414113 [01:09<00:39, 2842.93it/s]\u001b[A\n",
      " 73%|███████▎  | 301512/414113 [01:09<00:35, 3182.11it/s]\u001b[A\n",
      " 73%|███████▎  | 301953/414113 [01:10<00:32, 3472.12it/s]\u001b[A\n",
      " 73%|███████▎  | 302400/414113 [01:10<00:30, 3719.74it/s]\u001b[A\n",
      " 73%|███████▎  | 302843/414113 [01:10<00:28, 3906.90it/s]\u001b[A\n",
      " 73%|███████▎  | 303296/414113 [01:10<00:27, 4073.35it/s]\u001b[A\n",
      " 73%|███████▎  | 303737/414113 [01:10<00:26, 4168.07it/s]\u001b[A\n",
      " 73%|███████▎  | 304175/414113 [01:10<00:26, 4227.87it/s]\u001b[A\n",
      " 74%|███████▎  | 304612/414113 [01:10<00:25, 4258.69it/s]\u001b[A\n",
      " 74%|███████▎  | 305049/414113 [01:10<00:25, 4290.22it/s]\u001b[A\n",
      " 74%|███████▍  | 305492/414113 [01:10<00:25, 4330.91it/s]\u001b[A\n",
      " 74%|███████▍  | 305938/414113 [01:10<00:24, 4367.82it/s]\u001b[A\n",
      " 74%|███████▍  | 306379/414113 [01:11<00:24, 4316.18it/s]\u001b[A\n",
      " 74%|███████▍  | 306814/414113 [01:11<00:24, 4322.25it/s]\u001b[A\n",
      " 74%|███████▍  | 307252/414113 [01:11<00:24, 4338.54it/s]\u001b[A\n",
      " 74%|███████▍  | 307699/414113 [01:11<00:24, 4375.65it/s]\u001b[A\n",
      " 74%|███████▍  | 308145/414113 [01:11<00:24, 4399.59it/s]\u001b[A\n",
      " 75%|███████▍  | 308591/414113 [01:11<00:23, 4417.45it/s]\u001b[A\n",
      " 75%|███████▍  | 309034/414113 [01:11<00:24, 4374.65it/s]\u001b[A\n",
      " 75%|███████▍  | 309474/414113 [01:11<00:23, 4380.21it/s]\u001b[A\n",
      " 75%|███████▍  | 309918/414113 [01:11<00:23, 4397.26it/s]\u001b[A\n",
      " 75%|███████▍  | 310367/414113 [01:11<00:23, 4422.74it/s]\u001b[A\n",
      " 75%|███████▌  | 310814/414113 [01:12<00:23, 4436.66it/s]\u001b[A\n",
      " 75%|███████▌  | 311258/414113 [01:12<00:23, 4393.69it/s]\u001b[A\n",
      " 75%|███████▌  | 311704/414113 [01:12<00:23, 4412.67it/s]\u001b[A\n",
      " 75%|███████▌  | 312146/414113 [01:12<00:23, 4403.79it/s]\u001b[A\n",
      " 75%|███████▌  | 312597/414113 [01:12<00:22, 4434.48it/s]\u001b[A\n",
      " 76%|███████▌  | 313041/414113 [01:12<00:22, 4435.64it/s]\u001b[A\n",
      " 76%|███████▌  | 313485/414113 [01:12<00:22, 4389.95it/s]\u001b[A\n",
      " 76%|███████▌  | 313925/414113 [01:12<00:22, 4386.69it/s]\u001b[A\n",
      " 76%|███████▌  | 314372/414113 [01:12<00:22, 4409.58it/s]\u001b[A\n",
      " 76%|███████▌  | 314824/414113 [01:12<00:22, 4439.29it/s]\u001b[A\n",
      " 76%|███████▌  | 315272/414113 [01:13<00:22, 4450.47it/s]\u001b[A\n",
      " 76%|███████▌  | 315719/414113 [01:13<00:22, 4454.47it/s]\u001b[A\n",
      " 76%|███████▋  | 316168/414113 [01:13<00:21, 4462.37it/s]\u001b[A\n",
      " 76%|███████▋  | 316623/414113 [01:13<00:21, 4485.52it/s]\u001b[A\n",
      " 77%|███████▋  | 317076/414113 [01:13<00:21, 4498.26it/s]\u001b[A\n",
      " 77%|███████▋  | 317540/414113 [01:13<00:21, 4539.27it/s]\u001b[A\n",
      " 77%|███████▋  | 317995/414113 [01:13<00:21, 4507.53it/s]\u001b[A\n",
      " 77%|███████▋  | 318446/414113 [01:13<00:21, 4467.70it/s]\u001b[A\n",
      " 77%|███████▋  | 318898/414113 [01:13<00:21, 4481.03it/s]\u001b[A\n",
      " 77%|███████▋  | 319351/414113 [01:13<00:21, 4494.50it/s]\u001b[A\n",
      " 77%|███████▋  | 319801/414113 [01:14<00:20, 4494.73it/s]\u001b[A\n",
      " 77%|███████▋  | 320251/414113 [01:14<00:20, 4481.45it/s]\u001b[A\n",
      " 77%|███████▋  | 320700/414113 [01:14<00:21, 4443.23it/s]\u001b[A\n",
      " 78%|███████▊  | 321150/414113 [01:14<00:20, 4458.24it/s]\u001b[A\n",
      " 78%|███████▊  | 321603/414113 [01:14<00:20, 4478.18it/s]\u001b[A\n",
      " 78%|███████▊  | 322051/414113 [01:14<00:20, 4468.92it/s]\u001b[A\n",
      " 78%|███████▊  | 322500/414113 [01:14<00:20, 4473.20it/s]\u001b[A\n",
      " 78%|███████▊  | 322955/414113 [01:14<00:20, 4494.04it/s]\u001b[A\n",
      " 78%|███████▊  | 323411/414113 [01:14<00:20, 4512.11it/s]\u001b[A\n",
      " 78%|███████▊  | 323870/414113 [01:14<00:19, 4534.38it/s]\u001b[A\n",
      " 78%|███████▊  | 324324/414113 [01:15<00:20, 4470.75it/s]\u001b[A\n",
      " 78%|███████▊  | 324772/414113 [01:15<00:20, 4446.53it/s]\u001b[A\n",
      " 79%|███████▊  | 325217/414113 [01:15<00:20, 4423.69it/s]\u001b[A\n",
      " 79%|███████▊  | 325660/414113 [01:15<00:20, 4396.81it/s]\u001b[A\n",
      " 79%|███████▊  | 326108/414113 [01:15<00:19, 4420.02it/s]\u001b[A\n",
      " 79%|███████▉  | 326555/414113 [01:15<00:19, 4432.18it/s]\u001b[A\n",
      " 79%|███████▉  | 326999/414113 [01:15<00:19, 4432.95it/s]\u001b[A\n",
      " 79%|███████▉  | 327443/414113 [01:15<00:19, 4428.38it/s]\u001b[A\n",
      " 79%|███████▉  | 327886/414113 [01:15<00:19, 4416.38it/s]\u001b[A\n",
      " 79%|███████▉  | 328331/414113 [01:15<00:19, 4423.84it/s]\u001b[A\n",
      " 79%|███████▉  | 328774/414113 [01:16<00:19, 4403.20it/s]\u001b[A\n",
      " 79%|███████▉  | 329215/414113 [01:16<00:19, 4353.99it/s]\u001b[A\n",
      " 80%|███████▉  | 329651/414113 [01:16<00:19, 4345.24it/s]\u001b[A\n",
      " 80%|███████▉  | 330086/414113 [01:16<00:19, 4288.04it/s]\u001b[A\n",
      " 80%|███████▉  | 330516/414113 [01:16<00:19, 4268.21it/s]\u001b[A\n",
      " 80%|███████▉  | 330946/414113 [01:16<00:19, 4277.38it/s]\u001b[A\n",
      " 80%|████████  | 331374/414113 [01:16<00:19, 4270.23it/s]\u001b[A\n",
      " 80%|████████  | 331803/414113 [01:16<00:19, 4273.19it/s]\u001b[A\n",
      " 80%|████████  | 332238/414113 [01:16<00:19, 4294.78it/s]\u001b[A\n",
      " 80%|████████  | 332675/414113 [01:16<00:18, 4315.22it/s]\u001b[A\n",
      " 80%|████████  | 333110/414113 [01:17<00:18, 4323.65it/s]\u001b[A\n",
      " 81%|████████  | 333562/414113 [01:17<00:18, 4377.62it/s]\u001b[A\n",
      " 81%|████████  | 334000/414113 [01:17<00:18, 4357.36it/s]\u001b[A\n",
      " 81%|████████  | 334438/414113 [01:17<00:18, 4363.09it/s]\u001b[A\n",
      " 81%|████████  | 334879/414113 [01:17<00:18, 4376.73it/s]\u001b[A\n",
      " 81%|████████  | 335320/414113 [01:17<00:17, 4382.35it/s]\u001b[A\n",
      " 81%|████████  | 335759/414113 [01:17<00:17, 4353.35it/s]\u001b[A\n",
      " 81%|████████  | 336197/414113 [01:17<00:17, 4359.30it/s]\u001b[A\n",
      " 81%|████████▏ | 336639/414113 [01:17<00:17, 4375.39it/s]\u001b[A\n",
      " 81%|████████▏ | 337077/414113 [01:17<00:17, 4368.33it/s]\u001b[A\n",
      " 82%|████████▏ | 337514/414113 [01:18<00:17, 4344.99it/s]\u001b[A\n",
      " 82%|████████▏ | 337949/414113 [01:18<00:17, 4306.30it/s]\u001b[A\n",
      " 82%|████████▏ | 338380/414113 [01:18<00:18, 4121.53it/s]\u001b[A\n",
      " 82%|████████▏ | 338803/414113 [01:18<00:18, 4152.75it/s]\u001b[A\n",
      " 82%|████████▏ | 339237/414113 [01:18<00:17, 4204.78it/s]\u001b[A\n",
      " 82%|████████▏ | 339675/414113 [01:18<00:17, 4254.74it/s]\u001b[A\n",
      " 82%|████████▏ | 340104/414113 [01:18<00:17, 4264.38it/s]\u001b[A\n",
      " 82%|████████▏ | 340550/414113 [01:18<00:17, 4320.16it/s]\u001b[A\n",
      " 82%|████████▏ | 340992/414113 [01:18<00:16, 4348.29it/s]\u001b[A\n",
      " 82%|████████▏ | 341428/414113 [01:19<00:16, 4287.27it/s]\u001b[A\n",
      " 83%|████████▎ | 341858/414113 [01:19<00:16, 4270.41it/s]\u001b[A\n",
      " 83%|████████▎ | 342286/414113 [01:19<00:16, 4268.06it/s]\u001b[A\n",
      " 83%|████████▎ | 342732/414113 [01:19<00:16, 4322.24it/s]\u001b[A\n",
      " 83%|████████▎ | 343178/414113 [01:19<00:16, 4361.83it/s]\u001b[A\n",
      " 83%|████████▎ | 343615/414113 [01:19<00:16, 4335.03it/s]\u001b[A\n",
      " 83%|████████▎ | 344058/414113 [01:19<00:16, 4362.92it/s]\u001b[A\n",
      " 83%|████████▎ | 344495/414113 [01:19<00:16, 4349.23it/s]\u001b[A\n",
      " 83%|████████▎ | 344939/414113 [01:19<00:15, 4374.73it/s]\u001b[A\n",
      " 83%|████████▎ | 345389/414113 [01:19<00:15, 4408.98it/s]\u001b[A\n",
      " 84%|████████▎ | 345832/414113 [01:20<00:15, 4412.22it/s]\u001b[A\n",
      " 84%|████████▎ | 346274/414113 [01:20<00:15, 4412.19it/s]\u001b[A\n",
      " 84%|████████▎ | 346716/414113 [01:20<00:15, 4367.59it/s]\u001b[A\n",
      " 84%|████████▍ | 347153/414113 [01:20<00:15, 4342.01it/s]\u001b[A\n",
      " 84%|████████▍ | 347588/414113 [01:20<00:15, 4342.10it/s]\u001b[A\n",
      " 84%|████████▍ | 348023/414113 [01:20<00:15, 4328.32it/s]\u001b[A\n",
      " 84%|████████▍ | 348456/414113 [01:20<00:15, 4307.22it/s]\u001b[A\n",
      " 84%|████████▍ | 348887/414113 [01:20<00:15, 4302.29it/s]\u001b[A\n",
      " 84%|████████▍ | 349335/414113 [01:20<00:14, 4351.71it/s]\u001b[A\n",
      " 84%|████████▍ | 349778/414113 [01:20<00:14, 4374.88it/s]\u001b[A\n",
      " 85%|████████▍ | 350216/414113 [01:21<00:14, 4366.35it/s]\u001b[A\n",
      " 85%|████████▍ | 350653/414113 [01:21<00:14, 4359.44it/s]\u001b[A\n",
      " 85%|████████▍ | 351093/414113 [01:21<00:14, 4369.23it/s]\u001b[A\n",
      " 85%|████████▍ | 351530/414113 [01:21<00:14, 4356.65it/s]\u001b[A\n",
      " 85%|████████▍ | 351968/414113 [01:21<00:14, 4362.47it/s]\u001b[A\n",
      " 85%|████████▌ | 352405/414113 [01:21<00:14, 4338.65it/s]\u001b[A\n",
      " 85%|████████▌ | 352841/414113 [01:21<00:14, 4344.68it/s]\u001b[A\n",
      " 85%|████████▌ | 353276/414113 [01:21<00:14, 4317.70it/s]\u001b[A\n",
      " 85%|████████▌ | 353714/414113 [01:21<00:13, 4335.56it/s]\u001b[A\n",
      " 86%|████████▌ | 354154/414113 [01:21<00:13, 4352.23it/s]\u001b[A\n",
      " 86%|████████▌ | 354607/414113 [01:22<00:13, 4402.04it/s]\u001b[A\n",
      " 86%|████████▌ | 355048/414113 [01:22<00:13, 4371.30it/s]\u001b[A\n",
      " 86%|████████▌ | 355490/414113 [01:22<00:13, 4383.34it/s]\u001b[A\n",
      " 86%|████████▌ | 355929/414113 [01:22<00:13, 4371.17it/s]\u001b[A\n",
      " 86%|████████▌ | 356377/414113 [01:22<00:13, 4402.66it/s]\u001b[A\n",
      " 86%|████████▌ | 356818/414113 [01:22<00:13, 4355.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 357254/414113 [01:22<00:13, 4343.83it/s]\u001b[A\n",
      " 86%|████████▋ | 357698/414113 [01:22<00:12, 4370.10it/s]\u001b[A\n",
      " 86%|████████▋ | 358136/414113 [01:22<00:12, 4359.58it/s]\u001b[A\n",
      " 87%|████████▋ | 358594/414113 [01:22<00:12, 4421.90it/s]\u001b[A\n",
      " 87%|████████▋ | 359041/414113 [01:23<00:12, 4435.14it/s]\u001b[A\n",
      " 87%|████████▋ | 359485/414113 [01:23<00:12, 4388.83it/s]\u001b[A\n",
      " 87%|████████▋ | 359933/414113 [01:23<00:12, 4415.26it/s]\u001b[A\n",
      " 87%|████████▋ | 360375/414113 [01:23<00:12, 4407.46it/s]\u001b[A\n",
      " 87%|████████▋ | 360817/414113 [01:23<00:12, 4408.32it/s]\u001b[A\n",
      " 87%|████████▋ | 361258/414113 [01:23<00:13, 3985.36it/s]\u001b[A\n",
      " 87%|████████▋ | 361688/414113 [01:23<00:12, 4073.38it/s]\u001b[A\n",
      " 87%|████████▋ | 362119/414113 [01:23<00:12, 4141.14it/s]\u001b[A\n",
      " 88%|████████▊ | 362549/414113 [01:23<00:12, 4184.95it/s]\u001b[A\n",
      " 88%|████████▊ | 362971/414113 [01:24<00:12, 4086.65it/s]\u001b[A\n",
      " 88%|████████▊ | 363405/414113 [01:24<00:12, 4159.08it/s]\u001b[A\n",
      " 88%|████████▊ | 363841/414113 [01:24<00:11, 4217.11it/s]\u001b[A\n",
      " 88%|████████▊ | 364277/414113 [01:24<00:11, 4255.77it/s]\u001b[A\n",
      " 88%|████████▊ | 364718/414113 [01:24<00:11, 4298.84it/s]\u001b[A\n",
      " 88%|████████▊ | 365157/414113 [01:24<00:11, 4322.80it/s]\u001b[A\n",
      " 88%|████████▊ | 365591/414113 [01:24<00:11, 4303.39it/s]\u001b[A\n",
      " 88%|████████▊ | 366034/414113 [01:24<00:11, 4339.57it/s]\u001b[A\n",
      " 88%|████████▊ | 366469/414113 [01:24<00:11, 4292.62it/s]\u001b[A\n",
      " 89%|████████▊ | 366904/414113 [01:24<00:10, 4307.70it/s]\u001b[A\n",
      " 89%|████████▊ | 367336/414113 [01:25<00:10, 4306.88it/s]\u001b[A\n",
      " 89%|████████▉ | 367772/414113 [01:25<00:10, 4321.85it/s]\u001b[A\n",
      " 89%|████████▉ | 368213/414113 [01:25<00:10, 4344.88it/s]\u001b[A\n",
      " 89%|████████▉ | 368648/414113 [01:25<00:10, 4345.48it/s]\u001b[A\n",
      " 89%|████████▉ | 369083/414113 [01:25<00:10, 4326.09it/s]\u001b[A\n",
      " 89%|████████▉ | 369525/414113 [01:25<00:10, 4352.46it/s]\u001b[A\n",
      " 89%|████████▉ | 369971/414113 [01:25<00:10, 4381.57it/s]\u001b[A\n",
      " 89%|████████▉ | 370410/414113 [01:25<00:10, 4337.55it/s]\u001b[A\n",
      " 90%|████████▉ | 370844/414113 [01:25<00:10, 4083.17it/s]\u001b[A\n",
      " 90%|████████▉ | 371272/414113 [01:25<00:10, 4139.07it/s]\u001b[A\n",
      " 90%|████████▉ | 371707/414113 [01:26<00:10, 4198.59it/s]\u001b[A\n",
      " 90%|████████▉ | 372150/414113 [01:26<00:09, 4264.53it/s]\u001b[A\n",
      " 90%|████████▉ | 372581/414113 [01:26<00:09, 4277.20it/s]\u001b[A\n",
      " 90%|█████████ | 373019/414113 [01:26<00:09, 4305.85it/s]\u001b[A\n",
      " 90%|█████████ | 373455/414113 [01:26<00:09, 4321.21it/s]\u001b[A\n",
      " 90%|█████████ | 373897/414113 [01:26<00:09, 4350.29it/s]\u001b[A\n",
      " 90%|█████████ | 374336/414113 [01:26<00:09, 4361.38it/s]\u001b[A\n",
      " 91%|█████████ | 374773/414113 [01:26<00:09, 4346.17it/s]\u001b[A\n",
      " 91%|█████████ | 375208/414113 [01:26<00:09, 4293.81it/s]\u001b[A\n",
      " 91%|█████████ | 375638/414113 [01:26<00:09, 4226.09it/s]\u001b[A\n",
      " 91%|█████████ | 376062/414113 [01:27<00:08, 4229.44it/s]\u001b[A\n",
      " 91%|█████████ | 376486/414113 [01:27<00:08, 4221.26it/s]\u001b[A\n",
      " 91%|█████████ | 376909/414113 [01:27<00:08, 4221.22it/s]\u001b[A\n",
      " 91%|█████████ | 377332/414113 [01:27<00:08, 4204.78it/s]\u001b[A\n",
      " 91%|█████████ | 377771/414113 [01:27<00:08, 4256.51it/s]\u001b[A\n",
      " 91%|█████████▏| 378197/414113 [01:27<00:08, 4247.35it/s]\u001b[A\n",
      " 91%|█████████▏| 378632/414113 [01:27<00:08, 4275.88it/s]\u001b[A\n",
      " 92%|█████████▏| 379073/414113 [01:27<00:08, 4313.27it/s]\u001b[A\n",
      " 92%|█████████▏| 379505/414113 [01:27<00:08, 4222.68it/s]\u001b[A\n",
      " 92%|█████████▏| 379941/414113 [01:27<00:08, 4260.28it/s]\u001b[A\n",
      " 92%|█████████▏| 380380/414113 [01:28<00:07, 4298.19it/s]\u001b[A\n",
      " 92%|█████████▏| 380816/414113 [01:28<00:07, 4314.17it/s]\u001b[A\n",
      " 92%|█████████▏| 381264/414113 [01:28<00:07, 4360.29it/s]\u001b[A\n",
      " 92%|█████████▏| 381717/414113 [01:28<00:07, 4407.82it/s]\u001b[A\n",
      " 92%|█████████▏| 382163/414113 [01:28<00:07, 4422.92it/s]\u001b[A\n",
      " 92%|█████████▏| 382606/414113 [01:28<00:07, 4404.08it/s]\u001b[A\n",
      " 92%|█████████▏| 383047/414113 [01:28<00:07, 4397.30it/s]\u001b[A\n",
      " 93%|█████████▎| 383487/414113 [01:28<00:06, 4385.04it/s]\u001b[A\n",
      " 93%|█████████▎| 383926/414113 [01:28<00:06, 4377.15it/s]\u001b[A\n",
      " 93%|█████████▎| 384364/414113 [01:28<00:06, 4367.51it/s]\u001b[A\n",
      " 93%|█████████▎| 384801/414113 [01:29<00:06, 4328.66it/s]\u001b[A\n",
      " 93%|█████████▎| 385234/414113 [01:29<00:06, 4296.71it/s]\u001b[A\n",
      " 93%|█████████▎| 385668/414113 [01:29<00:06, 4309.10it/s]\u001b[A\n",
      " 93%|█████████▎| 386100/414113 [01:29<00:06, 4298.23it/s]\u001b[A\n",
      " 93%|█████████▎| 386549/414113 [01:29<00:06, 4352.20it/s]\u001b[A\n",
      " 93%|█████████▎| 386996/414113 [01:29<00:06, 4386.64it/s]\u001b[A\n",
      " 94%|█████████▎| 387445/414113 [01:29<00:06, 4415.35it/s]\u001b[A\n",
      " 94%|█████████▎| 387890/414113 [01:29<00:05, 4422.59it/s]\u001b[A\n",
      " 94%|█████████▍| 388333/414113 [01:29<00:05, 4414.53it/s]\u001b[A\n",
      " 94%|█████████▍| 388775/414113 [01:29<00:05, 4412.71it/s]\u001b[A\n",
      " 94%|█████████▍| 389217/414113 [01:30<00:05, 4408.81it/s]\u001b[A\n",
      " 94%|█████████▍| 389658/414113 [01:30<00:05, 4381.17it/s]\u001b[A\n",
      " 94%|█████████▍| 390097/414113 [01:30<00:05, 4333.55it/s]\u001b[A\n",
      " 94%|█████████▍| 390531/414113 [01:30<00:05, 4326.00it/s]\u001b[A\n",
      " 94%|█████████▍| 390968/414113 [01:30<00:05, 4337.43it/s]\u001b[A\n",
      " 95%|█████████▍| 391411/414113 [01:30<00:05, 4363.71it/s]\u001b[A\n",
      " 95%|█████████▍| 391856/414113 [01:30<00:05, 4387.08it/s]\u001b[A\n",
      " 95%|█████████▍| 392295/414113 [01:30<00:05, 4331.06it/s]\u001b[A\n",
      " 95%|█████████▍| 392729/414113 [01:30<00:04, 4325.15it/s]\u001b[A\n",
      " 95%|█████████▍| 393168/414113 [01:30<00:04, 4342.71it/s]\u001b[A\n",
      " 95%|█████████▌| 393603/414113 [01:31<00:04, 4328.49it/s]\u001b[A\n",
      " 95%|█████████▌| 394040/414113 [01:31<00:04, 4337.88it/s]\u001b[A\n",
      " 95%|█████████▌| 394474/414113 [01:31<00:04, 4323.00it/s]\u001b[A\n",
      " 95%|█████████▌| 394907/414113 [01:31<00:04, 4299.29it/s]\u001b[A\n",
      " 95%|█████████▌| 395338/414113 [01:31<00:04, 4190.15it/s]\u001b[A\n",
      " 96%|█████████▌| 395785/414113 [01:31<00:04, 4268.40it/s]\u001b[A\n",
      " 96%|█████████▌| 396213/414113 [01:31<00:04, 4217.02it/s]\u001b[A\n",
      " 96%|█████████▌| 396644/414113 [01:31<00:04, 4242.34it/s]\u001b[A\n",
      " 96%|█████████▌| 397083/414113 [01:31<00:03, 4283.00it/s]\u001b[A\n",
      " 96%|█████████▌| 397512/414113 [01:32<00:03, 4278.75it/s]\u001b[A\n",
      " 96%|█████████▌| 397941/414113 [01:32<00:03, 4264.85it/s]\u001b[A\n",
      " 96%|█████████▌| 398376/414113 [01:32<00:03, 4288.86it/s]\u001b[A\n",
      " 96%|█████████▋| 398817/414113 [01:32<00:03, 4324.40it/s]\u001b[A\n",
      " 96%|█████████▋| 399250/414113 [01:32<00:03, 4311.23it/s]\u001b[A\n",
      " 97%|█████████▋| 399687/414113 [01:32<00:03, 4328.49it/s]\u001b[A\n",
      " 97%|█████████▋| 400120/414113 [01:32<00:03, 4328.94it/s]\u001b[A\n",
      " 97%|█████████▋| 400553/414113 [01:32<00:03, 4233.31it/s]\u001b[A\n",
      " 97%|█████████▋| 401003/414113 [01:32<00:03, 4308.65it/s]\u001b[A\n",
      " 97%|█████████▋| 401453/414113 [01:32<00:02, 4363.78it/s]\u001b[A\n",
      " 97%|█████████▋| 401912/414113 [01:33<00:02, 4428.82it/s]\u001b[A\n",
      " 97%|█████████▋| 402356/414113 [01:33<00:02, 4409.06it/s]\u001b[A\n",
      " 97%|█████████▋| 402798/414113 [01:33<00:02, 4387.93it/s]\u001b[A\n",
      " 97%|█████████▋| 403238/414113 [01:33<00:02, 4348.91it/s]\u001b[A\n",
      " 97%|█████████▋| 403674/414113 [01:33<00:02, 4347.76it/s]\u001b[A\n",
      " 98%|█████████▊| 404117/414113 [01:33<00:02, 4372.02it/s]\u001b[A\n",
      " 98%|█████████▊| 404565/414113 [01:33<00:02, 4403.26it/s]\u001b[A\n",
      " 98%|█████████▊| 405006/414113 [01:33<00:02, 4354.04it/s]\u001b[A\n",
      " 98%|█████████▊| 405442/414113 [01:33<00:02, 4322.65it/s]\u001b[A\n",
      " 98%|█████████▊| 405883/414113 [01:33<00:01, 4347.44it/s]\u001b[A\n",
      " 98%|█████████▊| 406318/414113 [01:34<00:01, 4343.46it/s]\u001b[A\n",
      " 98%|█████████▊| 406764/414113 [01:34<00:01, 4375.45it/s]\u001b[A\n",
      " 98%|█████████▊| 407212/414113 [01:34<00:01, 4405.17it/s]\u001b[A\n",
      " 98%|█████████▊| 407666/414113 [01:34<00:01, 4444.09it/s]\u001b[A\n",
      " 99%|█████████▊| 408111/414113 [01:34<00:01, 4399.24it/s]\u001b[A\n",
      " 99%|█████████▊| 408556/414113 [01:34<00:01, 4413.06it/s]\u001b[A\n",
      " 99%|█████████▉| 408998/414113 [01:34<00:01, 4397.68it/s]\u001b[A\n",
      " 99%|█████████▉| 409443/414113 [01:34<00:01, 4411.33it/s]\u001b[A\n",
      " 99%|█████████▉| 409885/414113 [01:34<00:00, 4392.51it/s]\u001b[A\n",
      " 99%|█████████▉| 410331/414113 [01:34<00:00, 4410.36it/s]\u001b[A\n",
      " 99%|█████████▉| 410774/414113 [01:35<00:00, 4414.95it/s]\u001b[A\n",
      " 99%|█████████▉| 411216/414113 [01:35<00:00, 4402.49it/s]\u001b[A\n",
      " 99%|█████████▉| 411657/414113 [01:35<00:00, 4395.67it/s]\u001b[A\n",
      "100%|█████████▉| 412097/414113 [01:35<00:00, 4389.86it/s]\u001b[A\n",
      "100%|█████████▉| 412540/414113 [01:35<00:00, 4400.89it/s]\u001b[A\n",
      "100%|█████████▉| 412992/414113 [01:35<00:00, 4434.91it/s]\u001b[A\n",
      "100%|█████████▉| 413436/414113 [01:35<00:00, 4433.92it/s]\u001b[A\n",
      "100%|█████████▉| 413881/414113 [01:35<00:00, 4437.17it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:35<00:00, 4322.77it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4440064/102502400 [00:00<00:02, 44385126.44it/s]\u001b[A\n",
      " 12%|█▏        | 12541952/102502400 [00:00<00:01, 51344883.71it/s]\u001b[A\n",
      " 20%|██        | 20987904/102502400 [00:00<00:01, 58180125.43it/s]\u001b[A\n",
      " 29%|██▊       | 29253632/102502400 [00:00<00:01, 63844849.28it/s]\u001b[A\n",
      " 37%|███▋      | 38084608/102502400 [00:00<00:00, 69628603.11it/s]\u001b[A\n",
      " 44%|████▍     | 44867584/102502400 [00:00<00:00, 66704463.64it/s]\u001b[A\n",
      " 51%|█████▏    | 52592640/102502400 [00:00<00:00, 69549472.11it/s]\u001b[A\n",
      " 58%|█████▊    | 59760640/102502400 [00:00<00:00, 70171055.58it/s]\u001b[A\n",
      " 65%|██████▌   | 66756608/102502400 [00:00<00:00, 68971867.29it/s]\u001b[A\n",
      " 73%|███████▎  | 74801152/102502400 [00:01<00:00, 72025968.99it/s]\u001b[A\n",
      " 81%|████████  | 82993152/102502400 [00:01<00:00, 74705693.41it/s]\u001b[A\n",
      " 90%|████████▉ | 91914240/102502400 [00:01<00:00, 78522354.88it/s]\u001b[A\n",
      " 97%|█████████▋| 99852288/102502400 [00:01<00:00, 78407195.04it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:01<00:00, 75780452.50it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64            # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True     # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.bn.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer =torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 4.6741, Perplexity: 107.1343\n",
      "Epoch [1/3], Step [200/6471], Loss: 4.0065, Perplexity: 54.95493\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.8445, Perplexity: 46.73493\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.7882, Perplexity: 44.17709\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.4965, Perplexity: 33.0010\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.3525, Perplexity: 28.5751\n",
      "Epoch [1/3], Step [700/6471], Loss: 3.2105, Perplexity: 24.7906\n",
      "Epoch [1/3], Step [800/6471], Loss: 3.0784, Perplexity: 21.7231\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.9936, Perplexity: 19.9571\n",
      "Epoch [1/3], Step [1000/6471], Loss: 3.2779, Perplexity: 26.5196\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.7120, Perplexity: 15.0595\n",
      "Epoch [1/3], Step [1200/6471], Loss: 3.0186, Perplexity: 20.4618\n",
      "Epoch [1/3], Step [1300/6471], Loss: 3.0127, Perplexity: 20.3415\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.8876, Perplexity: 17.9503\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.5413, Perplexity: 12.6963\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.6024, Perplexity: 13.49617\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.6140, Perplexity: 13.6540\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.5074, Perplexity: 12.2735\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.7124, Perplexity: 15.06519\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.3216, Perplexity: 10.1921\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.4051, Perplexity: 11.0791\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.7219, Perplexity: 15.2091\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.4670, Perplexity: 11.7870\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.4183, Perplexity: 11.2273\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.6228, Perplexity: 13.7741\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.3940, Perplexity: 10.9576\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.3578, Perplexity: 10.5676\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.2159, Perplexity: 9.16969\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.8038, Perplexity: 16.5078\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.5046, Perplexity: 12.2391\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.4479, Perplexity: 11.5640\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.3729, Perplexity: 10.7283\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.2818, Perplexity: 9.794522\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.2740, Perplexity: 9.71787\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.5032, Perplexity: 12.2217\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.1333, Perplexity: 8.44246\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.3175, Perplexity: 10.1499\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.2573, Perplexity: 9.557455\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.1599, Perplexity: 8.67067\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.1451, Perplexity: 8.54299\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.0865, Perplexity: 8.05680\n",
      "Epoch [1/3], Step [4200/6471], Loss: 2.1538, Perplexity: 8.61712\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.2605, Perplexity: 9.58816\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.1983, Perplexity: 9.01012\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.2178, Perplexity: 9.18680\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.2817, Perplexity: 9.79352\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.1597, Perplexity: 8.66903\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.3692, Perplexity: 10.6890\n",
      "Epoch [1/3], Step [4900/6471], Loss: 2.3423, Perplexity: 10.4048\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.1280, Perplexity: 8.39786\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.4031, Perplexity: 11.0576\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.1025, Perplexity: 8.18686\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.4022, Perplexity: 11.0469\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.2641, Perplexity: 9.62219\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.0732, Perplexity: 7.94992\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.2281, Perplexity: 9.28264\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.0602, Perplexity: 7.84783\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.0516, Perplexity: 7.78046\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.0679, Perplexity: 7.90797\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.0243, Perplexity: 7.57054\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.2008, Perplexity: 9.03184\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.2054, Perplexity: 9.07409\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.2229, Perplexity: 9.23435\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.0719, Perplexity: 7.93998\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.3842, Perplexity: 10.85094\n",
      "Epoch [2/3], Step [200/6471], Loss: 2.2138, Perplexity: 9.15051\n",
      "Epoch [2/3], Step [300/6471], Loss: 2.2816, Perplexity: 9.79250\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.2652, Perplexity: 9.63316\n",
      "Epoch [2/3], Step [500/6471], Loss: 2.1917, Perplexity: 8.95086\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.1469, Perplexity: 8.55833\n",
      "Epoch [2/3], Step [700/6471], Loss: 2.3720, Perplexity: 10.7193\n",
      "Epoch [2/3], Step [800/6471], Loss: 2.2155, Perplexity: 9.16609\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.0734, Perplexity: 7.95205\n",
      "Epoch [2/3], Step [1000/6471], Loss: 1.8312, Perplexity: 6.2416\n",
      "Epoch [2/3], Step [1100/6471], Loss: 2.7152, Perplexity: 15.1079\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.3365, Perplexity: 10.3452\n",
      "Epoch [2/3], Step [1300/6471], Loss: 1.9241, Perplexity: 6.84894\n",
      "Epoch [2/3], Step [1400/6471], Loss: 2.1433, Perplexity: 8.52738\n",
      "Epoch [2/3], Step [1500/6471], Loss: 2.2132, Perplexity: 9.14499\n",
      "Epoch [2/3], Step [1600/6471], Loss: 2.0728, Perplexity: 7.94697\n",
      "Epoch [2/3], Step [1700/6471], Loss: 2.0872, Perplexity: 8.06234\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.0061, Perplexity: 7.43455\n",
      "Epoch [2/3], Step [1900/6471], Loss: 2.2154, Perplexity: 9.16502\n",
      "Epoch [2/3], Step [2000/6471], Loss: 2.0444, Perplexity: 7.72478\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.0548, Perplexity: 7.80560\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.0206, Perplexity: 7.54271\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.2486, Perplexity: 9.47464\n",
      "Epoch [2/3], Step [2400/6471], Loss: 2.1940, Perplexity: 8.97144\n",
      "Epoch [2/3], Step [2500/6471], Loss: 2.0737, Perplexity: 7.95395\n",
      "Epoch [2/3], Step [2600/6471], Loss: 2.0705, Perplexity: 7.92863\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.8860, Perplexity: 17.9213\n",
      "Epoch [2/3], Step [2800/6471], Loss: 1.8878, Perplexity: 6.60453\n",
      "Epoch [2/3], Step [2900/6471], Loss: 2.2998, Perplexity: 9.97238\n",
      "Epoch [2/3], Step [3000/6471], Loss: 1.9919, Perplexity: 7.32986\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.1507, Perplexity: 8.59063\n",
      "Epoch [2/3], Step [3200/6471], Loss: 1.9185, Perplexity: 6.81056\n",
      "Epoch [2/3], Step [3300/6471], Loss: 1.9371, Perplexity: 6.93874\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.1014, Perplexity: 8.17732\n",
      "Epoch [2/3], Step [3500/6471], Loss: 2.4220, Perplexity: 11.2689\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.6009, Perplexity: 13.4758\n",
      "Epoch [2/3], Step [3700/6471], Loss: 2.0499, Perplexity: 7.76694\n",
      "Epoch [2/3], Step [3800/6471], Loss: 1.9345, Perplexity: 6.92071\n",
      "Epoch [2/3], Step [3900/6471], Loss: 2.1549, Perplexity: 8.62744\n",
      "Epoch [2/3], Step [4000/6471], Loss: 2.0144, Perplexity: 7.49628\n",
      "Epoch [2/3], Step [4100/6471], Loss: 1.9560, Perplexity: 7.07089\n",
      "Epoch [2/3], Step [4200/6471], Loss: 2.2049, Perplexity: 9.06892\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.2526, Perplexity: 9.51210\n",
      "Epoch [2/3], Step [4400/6471], Loss: 1.9424, Perplexity: 6.97575\n",
      "Epoch [2/3], Step [4500/6471], Loss: 2.0846, Perplexity: 8.04144\n",
      "Epoch [2/3], Step [4600/6471], Loss: 2.0383, Perplexity: 7.67740\n",
      "Epoch [2/3], Step [4700/6471], Loss: 2.2593, Perplexity: 9.57683\n",
      "Epoch [2/3], Step [4800/6471], Loss: 2.1093, Perplexity: 8.24284\n",
      "Epoch [2/3], Step [4900/6471], Loss: 1.9878, Perplexity: 7.29961\n",
      "Epoch [2/3], Step [5000/6471], Loss: 2.8269, Perplexity: 16.8935\n",
      "Epoch [2/3], Step [5100/6471], Loss: 1.8038, Perplexity: 6.07265\n",
      "Epoch [2/3], Step [5200/6471], Loss: 2.1451, Perplexity: 8.54328\n",
      "Epoch [2/3], Step [5300/6471], Loss: 1.9421, Perplexity: 6.97340\n",
      "Epoch [2/3], Step [5400/6471], Loss: 2.1070, Perplexity: 8.22331\n",
      "Epoch [2/3], Step [5500/6471], Loss: 1.9386, Perplexity: 6.94909\n",
      "Epoch [2/3], Step [5600/6471], Loss: 2.1053, Perplexity: 8.20995\n",
      "Epoch [2/3], Step [5700/6471], Loss: 1.9482, Perplexity: 7.01587\n",
      "Epoch [2/3], Step [5800/6471], Loss: 2.2675, Perplexity: 9.65527\n",
      "Epoch [2/3], Step [5900/6471], Loss: 2.3017, Perplexity: 9.99166\n",
      "Epoch [2/3], Step [6000/6471], Loss: 2.0616, Perplexity: 7.85847\n",
      "Epoch [2/3], Step [6100/6471], Loss: 2.0090, Perplexity: 7.45629\n",
      "Epoch [2/3], Step [6200/6471], Loss: 1.9970, Perplexity: 7.36711\n",
      "Epoch [2/3], Step [6300/6471], Loss: 2.2448, Perplexity: 9.43908\n",
      "Epoch [2/3], Step [6400/6471], Loss: 2.2016, Perplexity: 9.03983\n",
      "Epoch [3/3], Step [100/6471], Loss: 1.8431, Perplexity: 6.316031\n",
      "Epoch [3/3], Step [200/6471], Loss: 1.9649, Perplexity: 7.13407\n",
      "Epoch [3/3], Step [300/6471], Loss: 1.9962, Perplexity: 7.36147\n",
      "Epoch [3/3], Step [400/6471], Loss: 1.9633, Perplexity: 7.12279\n",
      "Epoch [3/3], Step [500/6471], Loss: 1.9515, Perplexity: 7.03923\n",
      "Epoch [3/3], Step [600/6471], Loss: 2.3375, Perplexity: 10.3555\n",
      "Epoch [3/3], Step [700/6471], Loss: 2.3674, Perplexity: 10.6699\n",
      "Epoch [3/3], Step [800/6471], Loss: 1.8925, Perplexity: 6.63596\n",
      "Epoch [3/3], Step [900/6471], Loss: 2.0133, Perplexity: 7.48821\n",
      "Epoch [3/3], Step [1000/6471], Loss: 2.1365, Perplexity: 8.4700\n",
      "Epoch [3/3], Step [1100/6471], Loss: 1.9543, Perplexity: 7.05914\n",
      "Epoch [3/3], Step [1200/6471], Loss: 2.0259, Perplexity: 7.58293\n",
      "Epoch [3/3], Step [1300/6471], Loss: 1.8752, Perplexity: 6.52203\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.4313, Perplexity: 11.3733\n",
      "Epoch [3/3], Step [1500/6471], Loss: 2.1072, Perplexity: 8.22487\n",
      "Epoch [3/3], Step [1600/6471], Loss: 2.0830, Perplexity: 8.02823\n",
      "Epoch [3/3], Step [1700/6471], Loss: 1.7807, Perplexity: 5.93388\n",
      "Epoch [3/3], Step [1800/6471], Loss: 2.7918, Perplexity: 16.3112\n",
      "Epoch [3/3], Step [1900/6471], Loss: 2.1327, Perplexity: 8.43746\n",
      "Epoch [3/3], Step [2000/6471], Loss: 2.2489, Perplexity: 9.47715\n",
      "Epoch [3/3], Step [2100/6471], Loss: 1.9844, Perplexity: 7.27478\n",
      "Epoch [3/3], Step [2200/6471], Loss: 2.1484, Perplexity: 8.57081\n",
      "Epoch [3/3], Step [2300/6471], Loss: 1.8923, Perplexity: 6.63448\n",
      "Epoch [3/3], Step [2400/6471], Loss: 1.9970, Perplexity: 7.36728\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.0256, Perplexity: 7.58032\n",
      "Epoch [3/3], Step [2600/6471], Loss: 1.8221, Perplexity: 6.18476\n",
      "Epoch [3/3], Step [2700/6471], Loss: 1.9279, Perplexity: 6.87486\n",
      "Epoch [3/3], Step [2800/6471], Loss: 1.9868, Perplexity: 7.29246\n",
      "Epoch [3/3], Step [2900/6471], Loss: 2.0615, Perplexity: 7.85777\n",
      "Epoch [3/3], Step [3000/6471], Loss: 1.8491, Perplexity: 6.35388\n",
      "Epoch [3/3], Step [3100/6471], Loss: 2.3741, Perplexity: 10.7414\n",
      "Epoch [3/3], Step [3200/6471], Loss: 1.7529, Perplexity: 5.77127\n",
      "Epoch [3/3], Step [3300/6471], Loss: 1.8682, Perplexity: 6.47641\n",
      "Epoch [3/3], Step [3400/6471], Loss: 2.2340, Perplexity: 9.33697\n",
      "Epoch [3/3], Step [3500/6471], Loss: 2.0954, Perplexity: 8.12836\n",
      "Epoch [3/3], Step [3600/6471], Loss: 1.9257, Perplexity: 6.8599\n",
      "Epoch [3/3], Step [3700/6471], Loss: 1.9473, Perplexity: 7.00942\n",
      "Epoch [3/3], Step [3800/6471], Loss: 1.9034, Perplexity: 6.70842\n",
      "Epoch [3/3], Step [3900/6471], Loss: 1.9031, Perplexity: 6.70647\n",
      "Epoch [3/3], Step [4000/6471], Loss: 1.9146, Perplexity: 6.78446\n",
      "Epoch [3/3], Step [4100/6471], Loss: 2.0038, Perplexity: 7.41716\n",
      "Epoch [3/3], Step [4200/6471], Loss: 2.3273, Perplexity: 10.2507\n",
      "Epoch [3/3], Step [4300/6471], Loss: 2.1222, Perplexity: 8.34993\n",
      "Epoch [3/3], Step [4400/6471], Loss: 1.8975, Perplexity: 6.66935\n",
      "Epoch [3/3], Step [4500/6471], Loss: 1.8622, Perplexity: 6.43781\n",
      "Epoch [3/3], Step [4600/6471], Loss: 1.8674, Perplexity: 6.47125\n",
      "Epoch [3/3], Step [4700/6471], Loss: 1.8737, Perplexity: 6.51240\n",
      "Epoch [3/3], Step [4800/6471], Loss: 2.1347, Perplexity: 8.45468\n",
      "Epoch [3/3], Step [4900/6471], Loss: 2.0731, Perplexity: 7.94900\n",
      "Epoch [3/3], Step [5000/6471], Loss: 1.7489, Perplexity: 5.74829\n",
      "Epoch [3/3], Step [5100/6471], Loss: 1.7909, Perplexity: 5.99518\n",
      "Epoch [3/3], Step [5200/6471], Loss: 1.8937, Perplexity: 6.64374\n",
      "Epoch [3/3], Step [5300/6471], Loss: 1.9236, Perplexity: 6.84531\n",
      "Epoch [3/3], Step [5400/6471], Loss: 1.9988, Perplexity: 7.38046\n",
      "Epoch [3/3], Step [5500/6471], Loss: 1.8233, Perplexity: 6.19220\n",
      "Epoch [3/3], Step [5600/6471], Loss: 1.9783, Perplexity: 7.23032\n",
      "Epoch [3/3], Step [5700/6471], Loss: 2.3137, Perplexity: 10.1114\n",
      "Epoch [3/3], Step [5800/6471], Loss: 1.9552, Perplexity: 7.06515\n",
      "Epoch [3/3], Step [5900/6471], Loss: 1.9646, Perplexity: 7.13214\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.8380, Perplexity: 6.28387\n",
      "Epoch [3/3], Step [6100/6471], Loss: 1.7899, Perplexity: 5.98880\n",
      "Epoch [3/3], Step [6200/6471], Loss: 1.7150, Perplexity: 5.55663\n",
      "Epoch [3/3], Step [6300/6471], Loss: 1.8491, Perplexity: 6.35422\n",
      "Epoch [3/3], Step [6400/6471], Loss: 1.7513, Perplexity: 5.76249\n",
      "Epoch [3/3], Step [6471/6471], Loss: 1.9506, Perplexity: 7.03326"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
